{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qVeyQqooTzX"
      },
      "source": [
        "# Miguel Angel Ruiz Ortiz\n",
        "## Procesamiento de Lenguaje Natural\n",
        "## Tarea 2: Fundamentos de Minería de Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rj1lilONoTzZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/miguelruiz/Documents/Academic Stuff/NLP/Code/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/miguelruiz/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal\n",
        "from IPython.display import Markdown, display\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "import spacy\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kHC8cLpoTza"
      },
      "source": [
        "# 2- Bolsas de Palabras, Bigramas y Emociones\n",
        "\n",
        "### Representa los documentos y clasifica con SVM similar a la Práctica 3, pero con diferentes pesados de términos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd9UPGgxoTzb"
      },
      "source": [
        "La siguiente función lee un corpus y la clasificación de cada texto en él."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DUtgjUOroTzc"
      },
      "outputs": [],
      "source": [
        "def getCorpus(corpus_path: Path, labels_path: Path) -> tuple[list[str]]:\n",
        "    with open(corpus_path, \"r\") as corpus_file, open(labels_path, \"r\") as labels_file:\n",
        "        corpus = [line for line in corpus_file]\n",
        "        labels = [line for line in labels_file]\n",
        "\n",
        "    return corpus, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p80UL-gxoTzc"
      },
      "outputs": [],
      "source": [
        "base_path = Path(\"../data\")\n",
        "mex_a3t_path = base_path / \"MEX-A3T\"\n",
        "\n",
        "train_corpus_path = mex_a3t_path / \"mex20_train.txt\"\n",
        "train_labels_path = mex_a3t_path / \"mex20_train_labels.txt\"\n",
        "val_corpus_path = mex_a3t_path / \"mex20_val.txt\"\n",
        "val_labels_path = mex_a3t_path / \"mex20_val_labels.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uGSfOzq9oTzd"
      },
      "outputs": [],
      "source": [
        "train_corpus, train_labels = getCorpus(train_corpus_path, train_labels_path)\n",
        "val_corpus, val_labels = getCorpus(val_corpus_path, val_labels_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3_bMXmXoTzd"
      },
      "source": [
        "Número de tweets en el conjunto de entrenamiento y validación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnitTIPyoTze",
        "outputId": "dc4bc1c2-8f8d-4b47-94e8-609187635527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenamiento: 5278\n",
            "Validación: 587\n"
          ]
        }
      ],
      "source": [
        "print(\"Entrenamiento:\", len(train_corpus))\n",
        "print(\"Validación:\", len(val_corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjjVch_3uQzd"
      },
      "source": [
        "Histograma de las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "Teqhaq_uoTzf",
        "outputId": "810397bf-f8db-48ec-b730-d02002b8e4a9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.set_style(\"dark\") # para mejores gráficas\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "sns.countplot(data=pd.DataFrame(train_labels, columns=[\"etiqueta\"]), x=\"etiqueta\", ax=axs[0])\n",
        "sns.countplot(data=pd.DataFrame(val_labels, columns=[\"etiqueta\"]), x=\"etiqueta\", ax=axs[1])\n",
        "axs[0].set_title(\"Conjunto de entrenamiento\")\n",
        "axs[1].set_title(\"Conjunto de validación\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFxRYzyYoTzf"
      },
      "source": [
        "Vistazo a los datos en parejas (tweet, clasificación):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCg7LjEKoTzg",
        "outputId": "24de15ba-753c-42a0-8d61-be8bec49a281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('@USUARIO @USUARIO @USUARIO Q se puede esperar del maricon de closet de la Yañez aun recuerdo esa ves q lo vi en zona rosa viendo quien lo levantada\\n',\n",
              "  '1\\n'),\n",
              " ('@USUARIO La piel nueva siempre arde un poquito los primeros días... y más con este puto clima\\n',\n",
              "  '0\\n'),\n",
              " ('Ustedes no se enamoran de mí… por tontas.\\n', '1\\n'),\n",
              " ('Me las va a pagar esa puta gorda roba tuits...\\n', '1\\n'),\n",
              " ('@USUARIO LA GENTE ES TONTA PORQUE NO SE DAN CUENTA QUE TÚ HACES A BATMAN AZUL\\n',\n",
              "  '0\\n')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(train_corpus[:5], train_labels[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leg9BmTMoTzg"
      },
      "source": [
        "Procesamos las etiquetas para que no tengan \"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T09EEx_ooTzg"
      },
      "outputs": [],
      "source": [
        "train_labels = [int(label) for label in train_labels]\n",
        "val_labels = [int(label) for label in val_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR-NIvE4oTzh"
      },
      "source": [
        "Tokenizamos con TweetTokenizer. Como parámetros en el tokenizador especificamos que nos convierta a minúsculas el texto (```preserve_case=False```, que quite las palabras \"@usuario\" (```strip_handles=True```), y las secuencias con más de 3 caracteres iguales seguidos se cortan a longitud 3 (```reduce_len=True```)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DcAN-MwroTzh"
      },
      "outputs": [],
      "source": [
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
        "\n",
        "train_corpus_tk = [tokenizer.tokenize(tweet) for tweet in train_corpus]\n",
        "val_corpus_tk = [tokenizer.tokenize(tweet) for tweet in val_corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSM7NVCaoTzh"
      },
      "source": [
        "Para la Bolsa de Palabras (BoW), implementamos una clase que tenga los métodos:\n",
        "1. ``fit`` para extraer vocabulario y demás operaciones auxiliares que dependen de un conjunto de entrenamiento (lista de textos tokenizados), y regresa la matriz BoW asociada al conjunto de entrenamiento;\n",
        "2. ``transform`` para convertir una lista de textos tokenizados a su matriz BoW, después de haber llamado el método ``fit``.\n",
        "\n",
        "Los parámetros para inicializar la clase determinan el esquema de pesado (``weights_type``), si se necesitan normalizar los vectores asociados a los documentos (``normalize``), y el número de términos más frecuentes a considerar en el vocabulario de la BoW (``max_vocab_size``). Además, la clase contiene como atributos al vocabulario y la posición que le corresponde una palabra en el vocabulario en las columnas de la matriz BoW.\n",
        "\n",
        "Para extraer el vocabulario, no se consideran stopwords por ser palabras vacías que probablemente no contribuyan a la discriminación de los tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OmA8zb2oTzh"
      },
      "outputs": [],
      "source": [
        "def normalize_vector(vector: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normalize a 1D numpy array with l2 norm\"\"\"\n",
        "    norm = np.sum(vector**2) ** 0.5\n",
        "    # deal with case where norm is 0\n",
        "    if norm < 1e-8:\n",
        "        return vector\n",
        "\n",
        "    return vector / norm\n",
        "\n",
        "class BagOfWords:\n",
        "    def __init__(\n",
        "        self,\n",
        "        weights_type: Literal[\"binary\", \"tf\", \"tfidf\"] = \"binary\",\n",
        "        normalize: bool = False,\n",
        "        max_vocab_size: int = 5000,\n",
        "    ):\n",
        "\n",
        "        if weights_type not in [\"binary\", \"tf\", \"tfidf\"]:\n",
        "            raise ValueError(\n",
        "                'Invalid weights type. Must be one of \"binary\", \"tf\" or \"tfidf\"'\n",
        "            )\n",
        "\n",
        "        self.weights_type = weights_type\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.normalize = normalize\n",
        "        self.vocab = set()\n",
        "        self.vocab_order = {}  # word -> column index in the BoW matrix\n",
        "        self.word_freq = {}  # word -> frequency in the training corpus\n",
        "\n",
        "        # only for tfidf weights type. It precalculates the IDF termns which only depend on the training corpus\n",
        "        self.word_idf = {} # word -> IDF value after fit method\n",
        "\n",
        "    def fit(self, corpus: list[list[str]]) -> np.ndarray:\n",
        "        # extract vocabulary from training corpus and compute its BoW matrix\n",
        "\n",
        "        corpus_words = []\n",
        "        for doc in corpus:\n",
        "            corpus_words += doc\n",
        "\n",
        "        freq_dist = nltk.FreqDist(corpus_words)\n",
        "\n",
        "        stopwords_es = set(stopwords.words(\"spanish\"))\n",
        "\n",
        "        # obtain max_vocab_size most common words that are not stopwords\n",
        "\n",
        "        quit_stop_words = [\n",
        "            (word, freq)\n",
        "            for word, freq in freq_dist.most_common()\n",
        "            if word not in stopwords_es\n",
        "        ]\n",
        "\n",
        "        self.word_freq = dict(quit_stop_words[: self.max_vocab_size])\n",
        "        self.vocab_order = {\n",
        "            word: idx\n",
        "            for idx, (word, _) in enumerate(quit_stop_words[: self.max_vocab_size])\n",
        "        }\n",
        "        self.vocab = set(self.vocab_order.keys())\n",
        "\n",
        "        # reset the idf values for new fit\n",
        "        self.word_idf = {}\n",
        "\n",
        "        # construct the BoW matrix\n",
        "        return self.transform(corpus)\n",
        "\n",
        "    def transform(self, corpus: list[list[str]]) -> np.ndarray:\n",
        "        # compute BoW matrix for a given corpus, assuming vocabulary has been extracted\n",
        "\n",
        "        # validate this method is called after fit method\n",
        "        if len(self.vocab) == 0:\n",
        "            raise ValueError(\"Vocabulary has not been extracted in fit method yet\")\n",
        "\n",
        "        # construct the BoW matrix\n",
        "        if self.weights_type == \"binary\":\n",
        "            bow_matrix = self.bowBinary(corpus)\n",
        "        elif self.weights_type == \"tf\":\n",
        "            bow_matrix = self.bowTF(corpus)\n",
        "        else:\n",
        "            # tfidf case\n",
        "            bow_matrix = self.bowTFIDF(corpus)\n",
        "\n",
        "        if self.normalize:\n",
        "            for i in range(len(corpus)):\n",
        "                bow_matrix[i] = normalize_vector(bow_matrix[i])\n",
        "\n",
        "        return bow_matrix\n",
        "\n",
        "    def bowBinary(self, corpus: list[list[str]]) -> np.ndarray:\n",
        "        # compute BoW matrix with binary weights\n",
        "\n",
        "        bow_matrix = np.zeros((len(corpus), len(self.vocab)))\n",
        "\n",
        "        for id_doc, doc in enumerate(corpus):\n",
        "            for token in set(doc):\n",
        "                if token in self.vocab:\n",
        "                    bow_matrix[id_doc, self.vocab_order[token]] = 1\n",
        "\n",
        "        return bow_matrix\n",
        "\n",
        "    def bowTF(self, corpus: list[list[str]]) -> np.ndarray:\n",
        "        # compute BoW matrix with frequency weights\n",
        "\n",
        "        bow_matrix = np.zeros((len(corpus), len(self.vocab)))\n",
        "\n",
        "        for id_doc, doc in enumerate(corpus):\n",
        "            freq_doc = nltk.FreqDist(doc)\n",
        "\n",
        "            for token in doc:\n",
        "                if token in self.vocab:\n",
        "                    bow_matrix[id_doc, self.vocab_order[token]] = freq_doc[token]\n",
        "\n",
        "        return bow_matrix\n",
        "\n",
        "    def bowTFIDF(self, corpus: list[list[str]]) -> np.ndarray:\n",
        "        # compute BoW matrix with TF-IDF weights\n",
        "\n",
        "        bow_matrix = np.zeros((len(corpus), len(self.vocab)), dtype=float)\n",
        "\n",
        "        freq_all_docs = {i: nltk.FreqDist(doc) for i, doc in enumerate(corpus)}\n",
        "\n",
        "        # compute IDF for each token if it is first time (i.e., only for training phase)\n",
        "        if len(self.word_idf) == 0:\n",
        "            for token in self.vocab:\n",
        "                if sum([1 for i in range(len(corpus)) if token in freq_all_docs[i]]) == 0:\n",
        "                    print(token, self.word_freq[token])\n",
        "\n",
        "                self.word_idf[token] = np.log(\n",
        "                    len(corpus)\n",
        "                    / sum([1 for i in range(len(corpus)) if token in freq_all_docs[i]])\n",
        "                )\n",
        "\n",
        "        # construct matrix\n",
        "        for id_doc, doc in enumerate(corpus):\n",
        "            freq_doc = freq_all_docs[id_doc]\n",
        "\n",
        "            for token in doc:\n",
        "                if token in self.vocab:\n",
        "                    bow_matrix[id_doc, self.vocab_order[token]] = (\n",
        "                        freq_doc[token] * self.word_idf[token]\n",
        "                    )\n",
        "\n",
        "        return bow_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOm6_dal0TUY"
      },
      "source": [
        "La siguiente función evalua el rendimiento de una BoW (forma matricial) al clasificar con una SVM. Se escoge el mejor hiperparámetro ``C`` de la SVM entre los posibles valores ``[0.05, 0.12, 0.25, 0.5, 1, 2, 4]`` utilizando validación cruzada con 5 pliegues. La función regresa la mejor SVM ya entrenada, y un diccionario con las métricas de desempeño que devuelve la función ``classification_report`` de Scikit-Learn (e.g., accuracy, recall, precision, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_vbLD6DYoTzi"
      },
      "outputs": [],
      "source": [
        "def evaluate_bow(\n",
        "    X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray\n",
        ") -> tuple[svm.SVC, dict]:\n",
        "    \"\"\"Evaluates BoW matrix W using a linear SVM classifier and grid search for hyperparameter tuning\"\"\"\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        svm.SVC(kernel=\"linear\", class_weight=\"balanced\"),\n",
        "        {\"C\": [0.05, 0.12, 0.25, 0.5, 1, 2, 4]},\n",
        "        cv=5,\n",
        "        scoring=\"f1_macro\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    best_classifier = grid.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Mejor parámetro:\", grid.best_params_)\n",
        "\n",
        "    y_pred_val = best_classifier.predict(X_val)\n",
        "\n",
        "    print(\"Matriz de confusión:\\n\", confusion_matrix(y_val, y_pred_val))\n",
        "    print(\"Reporte de clasificación:\")\n",
        "    print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "    report_dict = classification_report(y_val, y_pred_val, output_dict=True)\n",
        "\n",
        "    return best_classifier, report_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQTeHZEwoTzi"
      },
      "source": [
        "### 2.1- Evalúe BoW con pesado binario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z3noGCJdoTzj"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"binary\", normalize=False)\n",
        "bow_tr_bin = bow_constructor.fit(train_corpus_tk)\n",
        "bow_val_bin = bow_constructor.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsrexRQioTzj",
        "outputId": "f3fcaa12-dcf0-4ef9-ba87-86701e7c5ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.12}\n",
            "Matriz de confusión:\n",
            " [[359  59]\n",
            " [ 40 129]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       418\n",
            "           1       0.69      0.76      0.72       169\n",
            "\n",
            "    accuracy                           0.83       587\n",
            "   macro avg       0.79      0.81      0.80       587\n",
            "weighted avg       0.84      0.83      0.83       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_bin, report_bin = evaluate_bow(\n",
        "    bow_tr_bin, train_labels, bow_val_bin, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JDR-mrvoTzj"
      },
      "source": [
        "### 2.2- Evalúe BoW con pesado frecuencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_Gw79VxyoTzj"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tf\", normalize=False)\n",
        "bow_tr_tf = bow_constructor.fit(train_corpus_tk)\n",
        "bow_val_tf = bow_constructor.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3ysiTBZOoTzk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.12}\n",
            "Matriz de confusión:\n",
            " [[356  62]\n",
            " [ 44 125]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87       418\n",
            "           1       0.67      0.74      0.70       169\n",
            "\n",
            "    accuracy                           0.82       587\n",
            "   macro avg       0.78      0.80      0.79       587\n",
            "weighted avg       0.83      0.82      0.82       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_tf, report_tf = evaluate_bow(\n",
        "    bow_tr_tf, train_labels, bow_val_tf, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFgZGHxBoTzk"
      },
      "source": [
        "### 2.3- Evalúe BoW con pesado TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rFSXrbUeoTzk"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tfidf\", normalize=False)\n",
        "bow_tr_tfidf = bow_constructor.fit(train_corpus_tk)\n",
        "bow_val_tfidf = bow_constructor.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CZP1bTGToTzk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.05}\n",
            "Matriz de confusión:\n",
            " [[358  60]\n",
            " [ 67 102]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       418\n",
            "           1       0.63      0.60      0.62       169\n",
            "\n",
            "    accuracy                           0.78       587\n",
            "   macro avg       0.74      0.73      0.73       587\n",
            "weighted avg       0.78      0.78      0.78       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_tfidf, report_tfidf = evaluate_bow(\n",
        "    bow_tr_tfidf, train_labels, bow_val_tfidf, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swzA3ZnIoTzk"
      },
      "source": [
        "### 2.4- Evalúe BoW con pesado binario normalizado l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "impS1zPAoTzl"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"binary\", normalize=True)\n",
        "bow_tr_bin_norm = bow_constructor.fit(train_corpus_tk)\n",
        "bow_val_bin_norm = bow_constructor.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3Jzp2QgLoTzl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 1}\n",
            "Matriz de confusión:\n",
            " [[355  63]\n",
            " [ 38 131]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.88       418\n",
            "           1       0.68      0.78      0.72       169\n",
            "\n",
            "    accuracy                           0.83       587\n",
            "   macro avg       0.79      0.81      0.80       587\n",
            "weighted avg       0.84      0.83      0.83       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_bin_norm, report_bin_norm = evaluate_bow(\n",
        "    bow_tr_bin_norm, train_labels, bow_val_bin_norm, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U15hTN16oTzl"
      },
      "source": [
        "### 2.5- Evalúe BoW con pesado frecuencia normalizado l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IrO_jD4moTzl"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tf\", normalize=True)\n",
        "bow_tr_tf_norm = bow_constructor.fit(train_corpus_tk)\n",
        "bow_val_tf_norm = bow_constructor.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e47OMiHSoTzl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 1}\n",
            "Matriz de confusión:\n",
            " [[356  62]\n",
            " [ 40 129]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.87       418\n",
            "           1       0.68      0.76      0.72       169\n",
            "\n",
            "    accuracy                           0.83       587\n",
            "   macro avg       0.79      0.81      0.80       587\n",
            "weighted avg       0.83      0.83      0.83       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_tf_norm, report_tf_norm = evaluate_bow(\n",
        "    bow_tr_tf_norm, train_labels, bow_val_tf_norm, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bJ88nY2oTzm"
      },
      "source": [
        "### 2.6- Evalúe BoW con pesado tfidf normalizado l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZhppLLjMoTzm"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tfidf\", normalize=True)\n",
        "bow_tr_tfidf_norm = bow_constructor.fit(train_corpus_tk)\n",
        "bow_val_tfidf_norm = bow_constructor.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CNkd58MCoTzm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.25}\n",
            "Matriz de confusión:\n",
            " [[365  53]\n",
            " [ 47 122]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       418\n",
            "           1       0.70      0.72      0.71       169\n",
            "\n",
            "    accuracy                           0.83       587\n",
            "   macro avg       0.79      0.80      0.79       587\n",
            "weighted avg       0.83      0.83      0.83       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_tfidf_norm, report_tfidf_norm = evaluate_bow(\n",
        "    bow_tr_tfidf_norm, train_labels, bow_val_tfidf_norm, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqBqFzewoTzm"
      },
      "source": [
        "### 2.7- Ponga una tabla comparativa a modo de resumen con las seis entradas anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para las métricas *precision*, *recall* y *F1-score*, se consideró la estrategia \"macro\" (i.e., el promedio de los F1-scores individuales de cada clase)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tfRDIjisoTzn"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "| Esquema de pesado | Accuracy | Precision | Recall | F1-Score |\n",
              "|-------------------|----------|-----------|--------|----------|\n",
              "| Binario | 0.83 | 0.79 | 0.81 | 0.80 |\n",
              "| TF | 0.82 | 0.78 | 0.80 | 0.79 |\n",
              "| TF-IDF | 0.78 | 0.74 | 0.73 | 0.73 |\n",
              "| Binario (normalizado) | 0.83 | 0.79 | 0.81 | 0.80 |\n",
              "| TF (normalizado) | 0.83 | 0.79 | 0.81 | 0.80 |\n",
              "| TF-IDF (normalizado) | 0.83 | 0.79 | 0.80 | 0.79 |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "| Esquema de pesado | Accuracy | Precision | Recall | F1-Score |\n",
        "|-------------------|----------|-----------|--------|----------|\n",
        "| Binario | {report_bin['accuracy']:.2f} | {report_bin['macro avg']['precision']:.2f} | {report_bin['macro avg']['recall']:.2f} | {report_bin['macro avg']['f1-score']:.2f} |\n",
        "| TF | {report_tf['accuracy']:.2f} | {report_tf['macro avg']['precision']:.2f} | {report_tf['macro avg']['recall']:.2f} | {report_tf['macro avg']['f1-score']:.2f} |\n",
        "| TF-IDF | {report_tfidf['accuracy']:.2f} | {report_tfidf['macro avg']['precision']:.2f} | {report_tfidf['macro avg']['recall']:.2f} | {report_tfidf['macro avg']['f1-score']:.2f} |\n",
        "| Binario (normalizado) | {report_bin_norm['accuracy']:.2f} | {report_bin_norm['macro avg']['precision']:.2f} | {report_bin_norm['macro avg']['recall']:.2f} | {report_bin_norm['macro avg']['f1-score']:.2f} |\n",
        "| TF (normalizado) | {report_tf_norm['accuracy']:.2f} | {report_tf_norm['macro avg']['precision']:.2f} | {report_tf_norm['macro avg']['recall']:.2f} | {report_tf_norm['macro avg']['f1-score']:.2f} |\n",
        "| TF-IDF (normalizado) | {report_tfidf_norm['accuracy']:.2f} | {report_tfidf_norm['macro avg']['precision']:.2f} | {report_tfidf_norm['macro avg']['recall']:.2f} | {report_tfidf_norm['macro avg']['f1-score']:.2f} |\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuT-DsMHoTzn"
      },
      "source": [
        "### 2.8- De las configuraciones anteriores elija la mejor y evalúela con más y menos términos (e.g., 1000 y 7000). Ponga una tabla dónde compare tres configuraciones distintas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos observar que los mejores pesados fueron binario, binario normalizado y por frecuencias (TF) normalizado. Vamos a escoger binario normalizado para los siguientes experimentos con 500 y 7000 palabras más frecuentes para el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "vpt0QUXVoTzn"
      },
      "outputs": [],
      "source": [
        "bow_constructor_2 = BagOfWords(weights_type=\"binary\", normalize=True, max_vocab_size=500)\n",
        "bow_constructor_3 = BagOfWords(weights_type=\"binary\", normalize=True, max_vocab_size=7000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "pwwt5LqloTzn"
      },
      "outputs": [],
      "source": [
        "bow_tr_bin_norm_2 = bow_constructor_2.fit(train_corpus_tk)\n",
        "bow_val_bin_norm_2 = bow_constructor_2.transform(val_corpus_tk)\n",
        "\n",
        "bow_tr_bin_norm_3 = bow_constructor_3.fit(train_corpus_tk)\n",
        "bow_val_bin_norm_3 = bow_constructor_3.transform(val_corpus_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "mal9aBSooTzn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 1}\n",
            "Matriz de confusión:\n",
            " [[359  59]\n",
            " [ 42 127]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       418\n",
            "           1       0.68      0.75      0.72       169\n",
            "\n",
            "    accuracy                           0.83       587\n",
            "   macro avg       0.79      0.81      0.80       587\n",
            "weighted avg       0.83      0.83      0.83       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_bin_norm_2, report_bin_norm_2 = evaluate_bow(\n",
        "    bow_tr_bin_norm_2, train_labels, bow_val_bin_norm_2, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "CfD39nI2oTzo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 1}\n",
            "Matriz de confusión:\n",
            " [[354  64]\n",
            " [ 39 130]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.87       418\n",
            "           1       0.67      0.77      0.72       169\n",
            "\n",
            "    accuracy                           0.82       587\n",
            "   macro avg       0.79      0.81      0.79       587\n",
            "weighted avg       0.83      0.82      0.83       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_bin_norm_3, report_bin_norm_3 = evaluate_bow(\n",
        "    bow_tr_bin_norm_3, train_labels, bow_val_bin_norm_3, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "| Tamaño de vocabulario | Accuracy | Precision | Recall | F1-Score |\n",
              "|----------------------|----------|-----------|--------|----------|\n",
              "| 500 | 0.83 | 0.79 | 0.81 | 0.80 |\n",
              "| 5000 | 0.83 | 0.79 | 0.81 | 0.80 |\n",
              "| 7000 | 0.82 | 0.79 | 0.81 | 0.79 |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "| Tamaño de vocabulario | Accuracy | Precision | Recall | F1-Score |\n",
        "|----------------------|----------|-----------|--------|----------|\n",
        "| 500 | {report_bin_norm_2['accuracy']:.2f} | {report_bin_norm_2['macro avg']['precision']:.2f} | {report_bin_norm_2['macro avg']['recall']:.2f} | {report_bin_norm_2['macro avg']['f1-score']:.2f} |\n",
        "| 5000 | {report_bin_norm['accuracy']:.2f} | {report_bin_norm['macro avg']['precision']:.2f} | {report_bin_norm['macro avg']['recall']:.2f} | {report_bin_norm['macro avg']['f1-score']:.2f} |\n",
        "| 7000 | {report_bin_norm_3['accuracy']:.2f} | {report_bin_norm_3['macro avg']['precision']:.2f} | {report_bin_norm_3['macro avg']['recall']:.2f} | {report_bin_norm_3['macro avg']['f1-score']:.2f} |\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGMBHb4XoTzo"
      },
      "source": [
        "### 2.9- Utilice el recurso léxico del Consejo Nacional de Investigación de Canadá llamado [\"EmoLex\"](https://www.saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) para construir una \"Bolsa de Emociones\" de los Tweets de agresividad (debe usar EmoLex en Español). Para esto, una estrategia sencilla sería enmascarar (sustituir) cada palabra con su emoción, y después construir la Bolsa de Emociones (BoE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "trh77CDzoTzo",
        "outputId": "89cf92ca-7340-4fdf-bd16-8775db934a35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English Word</th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "      <th>Spanish Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aback</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>detrás</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abacus</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ábaco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abandon</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>abandonar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abandoned</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>abandonado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abandonment</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abandono</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English Word  anger  anticipation  disgust  fear  joy  negative  positive  \\\n",
              "0        aback      0             0        0     0    0         0         0   \n",
              "1       abacus      0             0        0     0    0         0         0   \n",
              "2      abandon      0             0        0     1    0         1         0   \n",
              "3    abandoned      1             0        0     1    0         1         0   \n",
              "4  abandonment      1             0        0     1    0         1         0   \n",
              "\n",
              "   sadness  surprise  trust Spanish Word  \n",
              "0        0         0      0       detrás  \n",
              "1        0         0      1        ábaco  \n",
              "2        1         0      0    abandonar  \n",
              "3        1         0      0   abandonado  \n",
              "4        1         1      0     abandono  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emolex_path = base_path / \"NRC-Emotion-Lexicon\"\n",
        "emolex_spanish_path = emolex_path / \"OneFilePerLanguage\" / \"Spanish-NRC-EmoLex.txt\"\n",
        "\n",
        "emolex = pd.read_csv(emolex_spanish_path, sep='\\t')\n",
        "\n",
        "emolex.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y60WfknoTzp"
      },
      "source": [
        "Hacemos un mapeo de palabras a sus emociones asociadas en EmoLex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Q5ipaw2-oTzp",
        "outputId": "f756eed6-a923-4b8a-a11d-3e8306d761cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('detrás', []),\n",
              " ('ábaco', ['trust']),\n",
              " ('abandonar', ['negative']),\n",
              " ('abandonado', ['anger', 'sadness', 'negative']),\n",
              " ('abandono', ['anger', 'fear', 'surprise', 'sadness', 'negative'])]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotions = [\n",
        "    \"anger\",\n",
        "    \"anticipation\",\n",
        "    \"disgust\",\n",
        "    \"fear\",\n",
        "    \"joy\",\n",
        "    \"surprise\",\n",
        "    \"trust\",\n",
        "    \"sadness\",\n",
        "    \"positive\",\n",
        "    \"negative\",\n",
        "]\n",
        "\n",
        "word_to_emotions = {\n",
        "    row[\"Spanish Word\"]: [emotion for emotion in emotions if row[emotion] == 1]\n",
        "    for _, row in emolex.iterrows()\n",
        "}\n",
        "\n",
        "list(word_to_emotions.items())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVPpknEZoTzp"
      },
      "source": [
        "Usamos lematización para que poder hacer match con las palabras en EmoLex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "mpONG_pwoTzp"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "def lemmatize_spanish(text: str) -> list[str]:\n",
        "    \"\"\" Function to lemmatize text\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1gqxTfVUoTzp"
      },
      "outputs": [],
      "source": [
        "tr_lemmas = [lemmatize_spanish(tweet.lower()) for tweet in train_corpus]\n",
        "val_lemmas = [lemmatize_spanish(tweet.lower()) for tweet in val_corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29flyQd6oTzp"
      },
      "source": [
        "Enmascaramos cada palabra por sus emocines a través de nuestro mapeo anterior, e ignoramos las que no se pueden mapear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "krLKZj4ooTzp"
      },
      "outputs": [],
      "source": [
        "def get_doc_emotions(doc: list[str]) -> list[str]:\n",
        "    \"\"\" Function to get emotions from a document\n",
        "    \"\"\"\n",
        "    emotions = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token in word_to_emotions and len(word_to_emotions[token]) > 0:\n",
        "            emotions += word_to_emotions[token]\n",
        "\n",
        "    return emotions\n",
        "\n",
        "tr_masked = [get_doc_emotions(doc) for doc in tr_lemmas]\n",
        "val_masked = [get_doc_emotions(doc) for doc in val_lemmas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "WrT8JjM4oTzp",
        "outputId": "f754a3eb-c319-43d1-9dcd-553d34650947"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['anticipation', 'joy', 'surprise', 'trust', 'positive'],\n",
              " [],\n",
              " ['anticipation'],\n",
              " ['anger', 'anticipation', 'joy', 'trust', 'positive', 'disgust', 'negative'],\n",
              " ['negative', 'anticipation', 'sadness'],\n",
              " ['trust', 'positive'],\n",
              " [],\n",
              " ['anticipation',\n",
              "  'anticipation',\n",
              "  'anger',\n",
              "  'anticipation',\n",
              "  'disgust',\n",
              "  'fear',\n",
              "  'joy',\n",
              "  'surprise',\n",
              "  'trust',\n",
              "  'sadness',\n",
              "  'positive',\n",
              "  'negative',\n",
              "  'joy',\n",
              "  'surprise',\n",
              "  'trust',\n",
              "  'positive',\n",
              "  'negative',\n",
              "  'negative']]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_masked[:8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bolsa de Emociones (BoE) con pesado binario normalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "G6XRX7l-oTzp"
      },
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"binary\", normalize=True)\n",
        "\n",
        "boe_emolex_tr_bin = bow_constructor.fit(tr_masked)\n",
        "boe_emolex_val_bin = bow_constructor.transform(val_masked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BjuqsHProTzp",
        "outputId": "df60ce02-a38c-4304-89a2-fa572fda1962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.4472136 , 0.4472136 , 0.4472136 , 0.        ,\n",
              "        0.4472136 , 0.        , 0.        , 0.        , 0.4472136 ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.37796447, 0.37796447, 0.37796447, 0.37796447, 0.        ,\n",
              "        0.37796447, 0.37796447, 0.37796447, 0.        , 0.        ],\n",
              "       [0.57735027, 0.57735027, 0.        , 0.        , 0.57735027,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boe_emolex_tr_bin[:5, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVow4eS9oTzp"
      },
      "source": [
        "### 2.10- Usa tu BoE de alguna forma y clasifica con SVM. Ponga una tabla comparativa a modo de resumen con tres pesados (binario, TF, TF-IDF), normalize cada uno si lo cree conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4_qtYnAoTzq"
      },
      "source": [
        "Evaluación de pesado Binario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "bVADdiPfoTzq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.05}\n",
            "Matriz de confusión:\n",
            " [[327  91]\n",
            " [108  61]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       418\n",
            "           1       0.40      0.36      0.38       169\n",
            "\n",
            "    accuracy                           0.66       587\n",
            "   macro avg       0.58      0.57      0.57       587\n",
            "weighted avg       0.65      0.66      0.66       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_boe_emolex_bin, report_boe_emolex_bin = evaluate_bow(\n",
        "    boe_emolex_tr_bin, train_labels, boe_emolex_val_bin, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O6cTrnPoTzq"
      },
      "source": [
        "Pesado de frecuencia normalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HWl6cuLYoTzr",
        "outputId": "87b0eafc-9127-4961-9358-ab26e6d8c3cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.05}\n",
            "Matriz de confusión:\n",
            " [[336  82]\n",
            " [110  59]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.78       418\n",
            "           1       0.42      0.35      0.38       169\n",
            "\n",
            "    accuracy                           0.67       587\n",
            "   macro avg       0.59      0.58      0.58       587\n",
            "weighted avg       0.66      0.67      0.66       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tf\", normalize=True)\n",
        "\n",
        "boe_emolex_tr_tf = bow_constructor.fit(tr_masked)\n",
        "boe_emolex_val_tf = bow_constructor.transform(val_masked)\n",
        "\n",
        "classifier_boe_emolex_tf, report_boe_emolex_tf = evaluate_bow(\n",
        "    boe_emolex_tr_tf, train_labels, boe_emolex_val_tf, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgyyl7VoTzr"
      },
      "source": [
        "Pesado TF-IDF normalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kC00lPTLoTzr",
        "outputId": "40b76904-a969-4924-decb-f9edcf279678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.05}\n",
            "Matriz de confusión:\n",
            " [[328  90]\n",
            " [109  60]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77       418\n",
            "           1       0.40      0.36      0.38       169\n",
            "\n",
            "    accuracy                           0.66       587\n",
            "   macro avg       0.58      0.57      0.57       587\n",
            "weighted avg       0.65      0.66      0.65       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tfidf\", normalize=True)\n",
        "\n",
        "boe_emolex_tr_tfidf = bow_constructor.fit(tr_masked)\n",
        "boe_emolex_val_tfidf = bow_constructor.transform(val_masked)\n",
        "\n",
        "classifier_boe_emolex_tfidf, report_boe_emolex_tfidf = evaluate_bow(\n",
        "    boe_emolex_tr_tfidf, train_labels, boe_emolex_val_tfidf, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tabla comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "| Esquema de pesado | Accuracy | Precision | Recall | F1-Score |\n",
              "|-------------------|----------|-----------|--------|----------|\n",
              "| Binario | 0.66 | 0.58 | 0.57 | 0.57 |\n",
              "| TF | 0.67 | 0.59 | 0.58 | 0.58 |\n",
              "| TF-IDF | 0.66 | 0.58 | 0.57 | 0.57 |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "| Esquema de pesado | Accuracy | Precision | Recall | F1-Score |\n",
        "|-------------------|----------|-----------|--------|----------|\n",
        "| Binario | {report_boe_emolex_bin['accuracy']:.2f} | {report_boe_emolex_bin['macro avg']['precision']:.2f} | {report_boe_emolex_bin['macro avg']['recall']:.2f} | {report_boe_emolex_bin['macro avg']['f1-score']:.2f} |\n",
        "| TF | {report_boe_emolex_tf['accuracy']:.2f} | {report_boe_emolex_tf['macro avg']['precision']:.2f} | {report_boe_emolex_tf['macro avg']['recall']:.2f} | {report_boe_emolex_tf['macro avg']['f1-score']:.2f} |\n",
        "| TF-IDF | {report_boe_emolex_tfidf['accuracy']:.2f} | {report_boe_emolex_tfidf['macro avg']['precision']:.2f} | {report_boe_emolex_tfidf['macro avg']['recall']:.2f} | {report_boe_emolex_tfidf['macro avg']['f1-score']:.2f} |\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDrYbL29oTzr"
      },
      "source": [
        "# 3- Recurso Lingüístico de Emociones Mexicano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C869ImK3oTzr"
      },
      "source": [
        "### 3.1- Utilice el recurso léxico llamado [\"Spanish Emotion Lexicon (SEL)\"](https://www.cic.ipn.mx/~sidorov/#SEL) del Dr. Grigori Sidorov, profesor del Centro de Investigación en Computación (CIC) del Instituto Politécnico Nacional, para enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones con algún pesado (e.g., binario, TF, TF-IDF). Proponga alguna estrategia para incorporar el \"valor\" del \"Probability Factor of Affective use\" en su representación vectorial del documento. Evalúa y escribe una tabla comparativa a modo de resumen con al menos tres pesados: binario, frecuencia, TF-IDF. Normalize cada pesado según lo crea conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Leemos el archivo que contiene SEL mediante Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "i4ZVLPPEoTzr",
        "outputId": "0a8900fd-20e4-4da6-e87e-f1b4104b46f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Palabra</th>\n",
              "      <th>PFA</th>\n",
              "      <th>Categoría</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2026</th>\n",
              "      <td>tétrico</td>\n",
              "      <td>0.199</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2027</th>\n",
              "      <td>tormento</td>\n",
              "      <td>0.530</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2028</th>\n",
              "      <td>triste</td>\n",
              "      <td>0.966</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2029</th>\n",
              "      <td>tristemente</td>\n",
              "      <td>0.966</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2030</th>\n",
              "      <td>tristeza</td>\n",
              "      <td>0.966</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2031</th>\n",
              "      <td>trizas</td>\n",
              "      <td>0.464</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>vejación</td>\n",
              "      <td>0.297</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2033</th>\n",
              "      <td>vejar</td>\n",
              "      <td>0.396</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>vergonzoso</td>\n",
              "      <td>0.231</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>zangarriana</td>\n",
              "      <td>0.530</td>\n",
              "      <td>Tristeza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Palabra    PFA Categoría\n",
              "2026       tétrico  0.199  Tristeza\n",
              "2027      tormento  0.530  Tristeza\n",
              "2028        triste  0.966  Tristeza\n",
              "2029   tristemente  0.966  Tristeza\n",
              "2030      tristeza  0.966  Tristeza\n",
              "2031        trizas  0.464  Tristeza\n",
              "2032      vejación  0.297  Tristeza\n",
              "2033         vejar  0.396  Tristeza\n",
              "2034    vergonzoso  0.231  Tristeza\n",
              "2035  zangarriana   0.530  Tristeza"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sel_path = base_path / \"SpanishEmotionLexicon\" / \"SEL.txt\"\n",
        "\n",
        "sel = pd.read_csv(sel_path, sep='\\t', encoding='latin1')\n",
        "\n",
        "sel.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "RVDL2GcZoTzr"
      },
      "outputs": [],
      "source": [
        "sel.rename(columns={\" PFA\": \"PFA\"}, inplace=True) # Quitamos el espacio en blanco del nombre de la columna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Emociones consideradas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "BC-MECWvoTzr",
        "outputId": "2676e3a0-9de9-41d7-f1eb-d003ddea44a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Alegría', 'Enojo', 'Miedo', 'Repulsión', 'Sorpresa', 'Tristeza'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sel[\"Categoría\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construimos un mapeo \"palabra\" -> (\"emoción\", PFA), donde el PFA es el Probability Factor of Affective use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_E2Z8kwcoTzr",
        "outputId": "7163c1d4-7d27-4914-880c-275b745579c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('abundancia', ('Alegría', 0.83)),\n",
              " ('acabalar', ('Alegría', 0.396)),\n",
              " ('acallar', ('Alegría', 0.198)),\n",
              " ('acatar', ('Alegría', 0.198)),\n",
              " ('acción', ('Alegría', 0.397))]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_emotion_sel = {\n",
        "    row[\"Palabra\"]: (row[\"Categoría\"], row[\"PFA\"])\n",
        "    for _, row in sel.iterrows()\n",
        "}\n",
        "\n",
        "list(word_to_emotion_sel.items())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtenemos las máscaras de los tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "hLE1RIlqoTzs"
      },
      "outputs": [],
      "source": [
        "tr_masked = [\n",
        "    [word_to_emotion_sel[token][0] for token in doc if token in word_to_emotion_sel]\n",
        "    for doc in tr_lemmas\n",
        "]\n",
        "val_masked = [\n",
        "    [word_to_emotion_sel[token][0] for token in doc if token in word_to_emotion_sel]\n",
        "    for doc in val_lemmas\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las siguientes funciones realizan lo siguiente:\n",
        "1.  ``get_pfa_matrix``: construir una matriz con entradas PFA_ij, la suma de los PFA de cada palabra en el tweet i que asociada a la emoción j.\n",
        "2.  ``merge_boe_and_pfa``: dada la matriz PFA y la matriz BoE, se hace la multiplicación entrada por entrada (*element wise*) de ambas matrices, y se normaliza cada renglón de la matriz resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "cRRZxznvoTzs"
      },
      "outputs": [],
      "source": [
        "def get_pfa_matrix(docs: list[list[str]], emotions_order: dict[str, int]) -> np.ndarray:\n",
        "    \"\"\" Function to construct the PFA matrix. emotions_order is the map \"emotion\" -> \"column index\"\n",
        "    \"\"\"\n",
        "    pfa_matrix = np.zeros((len(docs), len(emotions_order)))\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        for token in doc:\n",
        "            if token in word_to_emotion_sel:\n",
        "                emotion, pfa = word_to_emotion_sel[token]\n",
        "                pfa_matrix[i, emotions_order[emotion]] += pfa\n",
        "\n",
        "    return pfa_matrix\n",
        "\n",
        "def merge_boe_and_pfa(docs: list[list[str]], boe_matrix: np.ndarray, emotions_order: dict[str, int]) -> np.ndarray:\n",
        "    \"\"\" Function to merge BoE and PFA matrices, which is the element-wise product of both matrices and normalize each row\n",
        "    \"\"\"\n",
        "    pfa_matrix = get_pfa_matrix(docs, emotions_order)\n",
        "\n",
        "    merged = boe_matrix*pfa_matrix # element wise product\n",
        "\n",
        "    # normalize each row\n",
        "    for i in range(merged.shape[0]):\n",
        "        merged[i] = normalize_vector(merged[i])\n",
        "\n",
        "    return merged\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UNmYFkAoTzs"
      },
      "source": [
        "Evaluación de BOE con pesado Binario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "UpJj2tOJoTzs"
      },
      "outputs": [],
      "source": [
        "# Bag of Emotions (BoE) construction\n",
        "bow_constructor = BagOfWords(weights_type=\"binary\", normalize=True)\n",
        "\n",
        "boe_sel_tr_bin = bow_constructor.fit(tr_masked)\n",
        "boe_sel_val_bin = bow_constructor.transform(val_masked)\n",
        "\n",
        "# add Probability Factor of Affective use (PFA) to the BoE matrix\n",
        "boe_pfa_tr_bin = merge_boe_and_pfa(tr_lemmas, boe_sel_tr_bin, bow_constructor.vocab_order)\n",
        "boe_pfa_val_bin = merge_boe_and_pfa(val_lemmas, boe_sel_val_bin, bow_constructor.vocab_order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "vrRh1htooTzs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 2}\n",
            "Matriz de confusión:\n",
            " [[166 252]\n",
            " [ 60 109]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.40      0.52       418\n",
            "           1       0.30      0.64      0.41       169\n",
            "\n",
            "    accuracy                           0.47       587\n",
            "   macro avg       0.52      0.52      0.46       587\n",
            "weighted avg       0.61      0.47      0.49       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_boe_pfa_bin, report_boe_pfa_bin = evaluate_bow(\n",
        "    boe_pfa_tr_bin, train_labels, boe_pfa_val_bin, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATOQEa8yoTzs"
      },
      "source": [
        "Evaluación de BOE con pesado de frecuencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "U-nIGoIOoTzs",
        "outputId": "9c2bedf1-6236-4881-ba1b-aad27d09f157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 4}\n",
            "Matriz de confusión:\n",
            " [[166 252]\n",
            " [ 60 109]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.40      0.52       418\n",
            "           1       0.30      0.64      0.41       169\n",
            "\n",
            "    accuracy                           0.47       587\n",
            "   macro avg       0.52      0.52      0.46       587\n",
            "weighted avg       0.61      0.47      0.49       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tf\", normalize=True)\n",
        "\n",
        "boe_sel_tr_tf = bow_constructor.fit(tr_masked)\n",
        "boe_sel_val_tf = bow_constructor.transform(val_masked)\n",
        "\n",
        "# add Probability Factor of Affective use (PFA) to the BoE matrix\n",
        "boe_pfa_tr_tf = merge_boe_and_pfa(tr_lemmas, boe_sel_tr_tf, bow_constructor.vocab_order)\n",
        "boe_pfa_val_tf = merge_boe_and_pfa(val_lemmas, boe_sel_val_tf, bow_constructor.vocab_order)\n",
        "\n",
        "classifier_boe_pfa_tf, report_boe_pfa_tf = evaluate_bow(\n",
        "    boe_pfa_tr_tf, train_labels, boe_pfa_val_tf, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv4-N0eaoTzt"
      },
      "source": [
        "Evaluación de BOE con pesado TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "xVYvPz9SoTzt",
        "outputId": "c21786af-09d1-428f-bd91-d0bd89262a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 2}\n",
            "Matriz de confusión:\n",
            " [[161 257]\n",
            " [ 57 112]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.39      0.51       418\n",
            "           1       0.30      0.66      0.42       169\n",
            "\n",
            "    accuracy                           0.47       587\n",
            "   macro avg       0.52      0.52      0.46       587\n",
            "weighted avg       0.61      0.47      0.48       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"tfidf\", normalize=True)\n",
        "\n",
        "boe_sel_tr_tfidf = bow_constructor.fit(tr_masked)\n",
        "boe_sel_val_tfidf = bow_constructor.transform(val_masked)\n",
        "\n",
        "# add Probability Factor of Affective use (PFA) to the BoE matrix\n",
        "boe_pfa_tr_tfidf = merge_boe_and_pfa(tr_lemmas, boe_sel_tr_tfidf, bow_constructor.vocab_order)\n",
        "boe_pfa_val_tfidf = merge_boe_and_pfa(val_lemmas, boe_sel_val_tfidf, bow_constructor.vocab_order)\n",
        "\n",
        "classifier_boe_pfa_tfidf, report_boe_pfa_tfidf = evaluate_bow(\n",
        "    boe_pfa_tr_tfidf, train_labels, boe_pfa_val_tfidf, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tabla comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "| Esquema de pesado | Accuracy | Precision | Recall | F1-Score |\n",
              "|-------------------|----------|-----------|--------|----------|\n",
              "| Binario | 0.47 | 0.52 | 0.52 | 0.46 |\n",
              "| TF | 0.47 | 0.52 | 0.52 | 0.46 |\n",
              "| TF-IDF | 0.47 | 0.52 | 0.52 | 0.46 |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "| Esquema de pesado | Accuracy | Precision | Recall | F1-Score |\n",
        "|-------------------|----------|-----------|--------|----------|\n",
        "| Binario | {report_boe_pfa_bin['accuracy']:.2f} | {report_boe_pfa_bin['macro avg']['precision']:.2f} | {report_boe_pfa_bin['macro avg']['recall']:.2f} | {report_boe_pfa_bin['macro avg']['f1-score']:.2f} |\n",
        "| TF | {report_boe_pfa_tf['accuracy']:.2f} | {report_boe_pfa_tf['macro avg']['precision']:.2f} | {report_boe_pfa_tf['macro avg']['recall']:.2f} | {report_boe_pfa_tf['macro avg']['f1-score']:.2f} |\n",
        "| TF-IDF | {report_boe_pfa_tfidf['accuracy']:.2f} | {report_boe_pfa_tfidf['macro avg']['precision']:.2f} | {report_boe_pfa_tfidf['macro avg']['recall']:.2f} | {report_boe_pfa_tfidf['macro avg']['f1-score']:.2f} |\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuUzp-GLoTzt"
      },
      "source": [
        "### 3.2- En un comentario aparte, discuta sobre la estrategía que utilizó para incorporar el \"Probability Factor of Affective use\". No más de 5 renglones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcVBJiA9oTzt"
      },
      "source": [
        "Para obtener la \"fuerza\" de asociación de un tweet con una emoción, podemos sumar el PFA de las palabras que están en el tweet (lematizadas) y que se relacionan con dicha emoción. Esto sería una BoE con una estrategia de pesado que generaliza a la del pesado con frecuencias (pues se obtiene cuando todas las relaciones \"palabra\" -> \"emoción\" tienen PFA igual a 1). Para obtener una mezcla de esta matriz PFA y la BoE usual, podemos multiplicar entrada por entrada ambas matrices. De esta manera, la entrada (i,j) de la matriz resultante es ``(suma_PFA)*(peso_BOE)``, lo cual es algo natural para establecer un peso final a la asociación del tweet i con la emoción j. Al final normalizamos cada renglón para que cada tweet tenga un vector unitario asociado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCYd-GWfoTzt"
      },
      "source": [
        "# 4- ¿Podemos mejorar con bigramas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQLWNzIvoTzt"
      },
      "source": [
        "### 4.1- Hacer un experimento dónde concatene una buena BoW según sus experimentos anteriores con otra BoW construida a partir de los 1000 bigramas más frecuentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bigrams(doc: list[str]) -> list[str]:\n",
        "    \"\"\" Function to get bigrams from a tokenized document\n",
        "    \"\"\"\n",
        "    \n",
        "    return [(doc[i], doc[i+1]) for i in range(len(doc)-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "DPE2TFzooTzt"
      },
      "outputs": [],
      "source": [
        "tr_bigrams = [list(bigrams(doc)) for doc in train_corpus_tk]\n",
        "val_bigrams = [list(bigrams(doc)) for doc in val_corpus_tk]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BoW con los 1000 bigramas más frecuentes, usando pesado binario normalizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "bow_constructor = BagOfWords(weights_type=\"binary\", normalize=True, max_vocab_size=1000)\n",
        "\n",
        "bow_bigrams_tr = bow_constructor.fit(tr_bigrams)\n",
        "bow_bigrams_val = bow_constructor.transform(val_bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Concatenamos y evaluamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "43d_FE4RoTzt",
        "outputId": "9e35e25b-7f26-4b19-f333-e2d064084b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.25}\n",
            "Matriz de confusión:\n",
            " [[361  57]\n",
            " [ 41 128]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       418\n",
            "           1       0.69      0.76      0.72       169\n",
            "\n",
            "    accuracy                           0.83       587\n",
            "   macro avg       0.79      0.81      0.80       587\n",
            "weighted avg       0.84      0.83      0.84       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bow_terms_bigrams_tr = np.concatenate((bow_tr_bin_norm_2, bow_bigrams_tr), axis=1)\n",
        "bow_terms_bigrams_val = np.concatenate((bow_val_bin_norm_2, bow_bigrams_val), axis=1)\n",
        "\n",
        "classifier_terms_bigrams, report_terms_bigrams = evaluate_bow(\n",
        "    bow_terms_bigrams_tr, train_labels, bow_terms_bigrams_val, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVEK5FVXoTzt"
      },
      "source": [
        "### 4.2- Hacer un experimento con las Bolsas de Emociones, Bolsa de Palabras y Bolsa de Bigramas; usted elige las dimensionalidades. Para construir la representación final del documento utilice la concatenación de las representaciones según sus observaciones (e.g., Bolsa de Palabras + Bolsa de Bigramas + Bolsa de Sentimientos de Canadá + Bolsa de Sentimientos de Grigori), y aliméntelas a un SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En las diferentes bolsas de palabras, bigramas y emociones se consideró el pesado binario normalizado, pues tuvo buen desempeño en general en los experimentos realizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "6dkUQVefoTzu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor parámetro: {'C': 0.5}\n",
            "Matriz de confusión:\n",
            " [[350  68]\n",
            " [ 41 128]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87       418\n",
            "           1       0.65      0.76      0.70       169\n",
            "\n",
            "    accuracy                           0.81       587\n",
            "   macro avg       0.77      0.80      0.78       587\n",
            "weighted avg       0.83      0.81      0.82       587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "aug_matrix_tr = np.concatenate((bow_tr_bin_norm_2, bow_bigrams_tr, boe_emolex_tr_bin, boe_pfa_tr_bin), axis=1)\n",
        "aug_matrix_val = np.concatenate((bow_val_bin_norm_2, bow_bigrams_val, boe_emolex_val_bin, boe_pfa_val_bin), axis=1)\n",
        "\n",
        "classifier_terms_bigrams, report_terms_bigrams = evaluate_bow(\n",
        "    aug_matrix_tr, train_labels, aug_matrix_val, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gKKVH1koTzu"
      },
      "source": [
        "### 4.3- Elabore conclusiones sobre toda esta Tarea, incluyendo observaciones, comentarios y posibles mejoras futuras. Discuta el comportamiento de la BoW de usar solo palabras a integrar bigramas, y luego a integrar todo. ¿Ayudó? o ¿empeoró?. Discuta también brevemente el costo computacional de los experimentos ¿Valió la pena tener todo?. Sea breve: todo en NO más de dos párrafos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En los experimentos de la BoW con diferentes pesados se observó que los mejores para esta tarea fueron el pesado binario, binario normalizado y de frecuencias normalizado, con un accuracy del 83%, precision del 79%, recall del 81% y F1 score del 80%. Tomando en pesado binario normalizado como base, después se notó que con un número modesto de palabras en el vocabulario, tomando las 500 más frecuentes, se obtenían exactamente los mismos resultados. Por otro lado, al subir el número de palabras a 7000, empeoró en un punto porcentual el accuracy y el F1-score, por lo que no ayuda aumentar el vocabulario al menos para esta tarea. Tal vez este comportamiento se obtuvo debido a que nosotros NO consideramos stopwords, y de haberlas considerado tal vez sí hubieramos visto un cambio al aumentar el vocabulario (pues las palabras más frecuentes son stopwords).\n",
        "\n",
        "En cuento a las bolsas de emociones con EmoLex y SEL, vimos que obtenían métricas más bajas (accuracy de 66-67% con EmoLex y 47% con SEL). Esto es razonable pues ambos recursos léxicos no tenían tantas palabras mapeadas a una emoción, lo que hacía que un tweet (que tiene en general pocas palabras) tenga muy pocas emociones asociadas e incluso muchos tweets sin ninguna emoción asociada. Finalmente, al concatenar la BoW con los bigramas y también con las bolsas de emociones, se observó que se seguían obteniendo métricas similares a la BoW normal con 500 palabras en el vocabulario. Por lo que no valió la pena integrar estos acercamientos extras para resolver el problema. El costo computacional aumentaba mucho conforme aumentaba la dimensión, por ejemplo cuando consideramos 7000 palabras el modelo se entrenó en local durante 80 minutos. Mientras que con 500 palabras se entrenaba en 1 minuto y ya se obtenían las mejores métricas de entre todos estos experimentos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
