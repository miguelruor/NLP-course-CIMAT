{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__m7w5bkvJmj"
      },
      "source": [
        "# Miguel Angel Ruiz Ortiz\n",
        "## Procesamiento de Lenguaje Natural\n",
        "## Tarea 4: Modelo de Lenguaje de Política"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "B-oUXZ5CvJmm"
      },
      "outputs": [],
      "source": [
        "from typing import Union, Optional\n",
        "from pathlib import Path\n",
        "from itertools import permutations\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5fNNsDZvMFc",
        "outputId": "0784d1b6-de19-4414-f69d-d51737b1baae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOspxzcGvJmn"
      },
      "source": [
        "Descarga de \"Punkt sentence tokenizer\" para poder dividir un texto en oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzxiLGMpvJmn",
        "outputId": "58f52144-654f-4be3-ca1e-a27347006eb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMJl-HVzvJmo"
      },
      "source": [
        "## 2- Textos de las Mañeras\n",
        "\n",
        "Tokeniza con alguna librería de tu elección para obtener oraciones y crear un corpus de miles de oraciones de todos los textos de las mañaneras. Construye un archivo de texto como el de los tuits, una oración por línea.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0AqdkinnvJmp"
      },
      "outputs": [],
      "source": [
        "base_path = Path(\"/content/drive/My Drive/Academic Stuff/NLP (CIMAT)/corpus\")\n",
        "amlo_conferences_path = base_path / \"conferencias-presidencia-mx\" / \"conferencias-amlo\"\n",
        "sheinbaum_conferences_path = base_path / \"conferencias-presidencia-mx\" / \"conferencias-sheinbaum\"\n",
        "all_corpus_path = base_path / \"mx_politics_corpus\" / \"corpus.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GUAcwk73vJmp"
      },
      "outputs": [],
      "source": [
        "def get_file_paths(dir_path: Path) -> list[str]:\n",
        "    \"\"\"\n",
        "      Get file paths from a given directory\n",
        "    \"\"\"\n",
        "    return list(dir_path.glob(\"*.txt\"))\n",
        "\n",
        "def get_corpus(file_paths: list[Path]) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Get corpus from a list of file paths, with .txt files, as a dictionary { file name -> file content }\n",
        "    \"\"\"\n",
        "    corpus = {}\n",
        "\n",
        "    for file in file_paths:\n",
        "      with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "        filename, _ = file.name.split(\".\") # we quit extension .txt from file name\n",
        "        text = f.read().replace(\"\\xa0\", \" \") # \\xa0 is a \"non-breaking space\" found through the text\n",
        "        corpus[filename] = text\n",
        "\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sDKv065hvJmq"
      },
      "outputs": [],
      "source": [
        "amlo_filenames = get_file_paths(amlo_conferences_path)\n",
        "shein_filenames = get_file_paths(sheinbaum_conferences_path)\n",
        "\n",
        "amlo_corpus = get_corpus(amlo_filenames)\n",
        "shein_corpus = get_corpus(shein_filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viYtunNovJmq",
        "outputId": "d5da572d-ed57-4c1a-aee4-bf23c1f8af8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07.12.18 Versión estenográfica de la conferencia de prensa matutina del presidente de México, Andrés Manuel López Obrador\n",
            "\n",
            "Descarga audio:  07-12-18 AUDIO CONFERENCIA DE PRENSA PRESIDENTE DE MÉXICO\n",
            "PALACIO NACIONAL, 07 de diciembre de 2018\n",
            "Versión estenográfica\n",
            " \n",
            "Conferencia de prensa del presidente\n"
          ]
        }
      ],
      "source": [
        "print(amlo_corpus[\"2018-12-07\"][:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IbC_MpzRvJmr"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "\n",
        "for key in amlo_corpus:\n",
        "    corpus.append(amlo_corpus[key])\n",
        "\n",
        "for key in shein_corpus:\n",
        "    corpus.append(shein_corpus[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "3L2KiuD9vJms",
        "outputId": "45849873-62bc-4482-d71e-57145560e9e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'25.02.21 Versión estenográfica de la conferencia de prensa matutina del presidente Andrés Manuel López Obrador\\n\\n2021: Año de la Independencia\\n \\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Buenos días. Se nos hizo un poco tarde, pero ya estamos aquí.\\nSólo tengo un tema que tratarles, de modo que vamos a tener tiempo de contestar preguntas de ustedes, informar a la gente, como siempre lo hacemos. Voy nada más a proceder a desahogar mi tema y luego ya nos vamos con las preguntas y las respuestas.\\nMiren, la Auditoría Superior de la Federación dio a conocer un informe y se aprovecharon nuestros adversarios, la prensa conservadora que defiende al régimen corrupto, para afectarnos en la imagen del gobierno, sobre todo en el caso de la cancelación del aeropuerto de Texcoco.\\nEntonces, no creo, aunque existe la posibilidad de que hayan hecho mal las cuentas, aun así, sería lamentable que la Auditoría de la Federación hiciera mal las cuentas; más bien, creo que se trata de una actitud politiquera, que buscaron dañarnos para complacer a nuestros opositores.\\n\\n\\n \\nEntonces, no vamos a dejar pasar este asunto, porque está de por medio la dignidad, y voy a enviar una carta a la diputada Dulce María Sauri Riancho, presidenta de la Mesa Directiva de la Cámara de Diputados, para que se inicie una investigación; todo, esto de manera respetuosa, porque la Auditoría Superior de la Federación depende de la Cámara de Diputados.\\nEntonces, dice así:\\n‘Diputada Dulce María Sauri Riancho, presidenta de la Mesa Directiva de la Cámara de Diputados. Presente.\\n‘Como seguramente es de su conocimiento, la Auditoría Superior de la Federación, que depende de la Cámara de Diputados, elaboró un informe tendencioso y falso sobre el procedimiento y el manejo de recursos del gobierno que presido.\\n‘En otras cosas, tal instancia difundió en los medios de información, en los medios informativos, que el costo de no construir el aeropuerto de Texcoco ascendía a 331 mil 991 millones de pesos, cuando en realidad la cifra fue de 110 807 millones de pesos, es decir, una tercera parte menos de lo publicado.\\n‘Tampoco consideró que terminar dicha obra significaba destinar cuando menos otros 300 mil millones de pesos y cancelar el actual aeropuerto de la Ciudad de México y la base aérea de Santa Lucía, mientras que el nuevo que estamos construyendo, además de hacerse en tierra firme y no en un lago, implicará una inversión de 75 mil millones de pesos, o sea, se tendrá un ahorro de 225 mii millones de pesos, lo cual demuestra que la decisión que se tomó fue la correcta y en completo beneficio de la hacienda pública.\\n‘Aun cuando los responsables de la Auditoría Superior de la Federación se han retractado ante tamaño absurdo, esgrimiendo que aplicaron mal sus métodos de proyección, considero que una actitud de este tipo no sólo obedece a una deficiencia técnica, sino también a una intencionalidad política, pues como sucedió, estas y otras falsedades contenidas en el informe fueron utilizadas por la oposición conservadora y por la prensa que defiende al antiguo régimen corrupto para trata de dañar la imagen de rectitud y honestidad de nuestro gobierno.\\n‘En consecuencia, le solicito de manera respetuosa y en observancia del principio de separación de poderes, y si para ello no tiene inconveniente, que se emprendan las acciones necesarias para impulsar una investigación que permita el esclarecimiento a fondo de las equívocas afirmaciones de la Auditoría Superior de la Federación y despeje la lamentable desinformación que el documento referido indujo en sectores de la opinión pública. Considero que tal solución es necesaria para servir a la causa de la transparencia y preservar el prestigio de las instituciones.’\\nEsto es lo que hoy le voy a enviar a la presidenta de la Cámara de Diputados.\\nEmpezamos. Después Sara, que escuché por ahí. Ah, aquí estás, pero primero tú.\\nPREGUNTA: Gracias, presidente. Buenos días. Pues para no perder el hilo…\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Ah, tengo… Sí, pero se queda en tercera ¿no?, ahorita.\\nINTERLOCUTOR: Gracias. Preguntarle sobre este tema. ¿De dónde considera que proviene esta intencionalidad política o esta búsqueda de afectar a su gobierno?, ¿directamente del auditor Colmenares?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: No quiero señalar a nadie, pido que se haga la investigación y que se aclare este asunto. Es que, imagínense, se da a conocer este informe, se filtran documentos, este documento del aeropuerto se filtró.\\nVean cómo lo manejó la prensa vendida o alquilada, los medios de información que están en contra nuestra, porque antes se beneficiaban cuando el antiguo régimen, vean el escándalo que hicieron, hasta intelectuales orgánicos, Elizondo, Héctor Aguilar Camín, o sea, los mismos, todos ellos del antiguo régimen, escritores, intelectuales orgánicos.\\nEste Elizondo era consejero de Pemex en el periodo neoliberal y Héctor Aguilar Camín era el jefe, junto con Krauze, de toda la política cultural, editorial del país; lo acaparaban todo, las becas para escritores, para artistas, tenían una gran influencia y eran subvencionados por el gobierno.\\nEntonces, con esta información se les da materia a estos medios de información y a articulistas e intelectuales orgánicos, que tienen un distintivo: son muy corruptos. El conservadurismo es sinónimo de autoritarismo y de corrupción, y la historia así lo demuestra, entonces hacen daño.\\nEntonces, no se trata de ir a la fiscalía a presentar una denuncia, sino que un poder independiente haga una revisión para fortalecer a las instituciones y que no se utilicen con propósitos políticos para afectar al gobierno o a la oposición.\\nQue se actúe con mucha responsabilidad, con mucha seriedad en todos estos casos y que se respete al pueblo, que no se mienta, que se le respete a la gente. Al final de cuentas nos debemos a pueblo y lo tenemos que respetar.\\nY un columnista, un periodista, un servidor público, pues tiene que hablar con la verdad y respetar al pueblo, independientemente de sus consideraciones o de sus preferencias políticas, ideológicas. Si se escribe, si es servidor público, por razones éticas se tiene que decir la verdad, no manipular, no engañar. Entonces eso es lo que queremos que no suceda.\\nNo es un asunto personal contra nadie de este organismo, es que en la Cámara de Diputados investiguen sobre este caso y sobre el comportamiento de esta institución.\\nINTERLOCUTOR: O sea, ¿usted considera que la Auditoría tendría una intencionalidad política de afectarlo a usted o a su gobierno?\\nY si considera que este error ameritaría promover la salida del auditor.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Eso lo va a decidir la Cámara de Diputados, no me corresponde a mí.\\nNosotros pensamos que no podíamos dejar pasar un asunto así, como no vamos a dejar pasar nada que signifique engañar a la gente, manipular, nada de falsear. La verdad nos hará libres.\\nINTERLOCUTOR: Gracias, presidente. Y si me permite tocar un segundo tema:\\nTanto ayer como hoy se dio a conocer una investigación relacionada con una red de contrabando de combustible del estado de Tamaulipas proveniente de Estados Unidos. Aparentemente, hay funcionarios estatales involucrados y sería parte de la investigación que involucra al gobernador de Tamaulipas.\\n¿Qué reporte tiene de esta red de combustible?, ¿y hasta dónde considera que están llegando estas complicidades en el gobierno estatal?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Mire, este asunto de la solicitud de la fiscalía para quitarle el fuero al gobernador de Tamaulipas pues ya está en la Cámara de Diputados y ese poder va a decidir, hay un procedimiento.\\nLa Cámara de Diputados determina si se puede someter a proceso al gobernador y va esa resolución de la cámara, -porque esto no se sabe- al Congreso de Tamaulipas y allá van a decidir si procede o no. Es un proceso muy transparente, abierto. Y luego va a empezar el juicio en el Poder Judicial de Tamaulipas, mientras el gobernador tenga fuero.\\nEntonces, hay que esperarnos para que la Cámara de Diputados resuelva y no agregarle más cosas de las que deben de estar consignadas en la denuncia que presentó la fiscalía a la Cámara de Diputados.\\nINTERLOCUTOR: ¿En particular sobre esta red de contrabando de combustible tiene algún reporte?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Siempre hemos estado combatiendo el huachicol, hemos logrado reducirlo en un 95 por ciento. Yo recuerdo a todos que se robaban hasta 80 mil barriles diarios de gasolinas cuando iniciamos el gobierno en noviembre, ese fue el robo que hubo, noviembre del 18.\\nEntramos y tomamos la decisión de combatir ese robo que estaba como tolerado, -para decir lo menos- permitido, y a partir de que se decidió combatir el huachicol se redujo a un promedio de cuatro mil barriles diarios; de 80 mil a cuatro mil y por ahí está, no hemos podido terminarlo.\\nY sí hay información de que se introduce combustible de contrabando por la frontera, pero no hay elementos hasta ahora. Se hacen las cuentas de cuánto se consume de combustible y aparece más combustible del que se consume y del que distribuye Pemex, entonces se mantiene la hipótesis de que es contrabando en combustible, pero no hay elementos; si hubiese elementos, ya se hubiesen denunciado.\\nINTERLOCUTOR: Presuntamente hay colusión de funcionarios estatales en esta red.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: No tenemos esa información.\\nINTERLOCUTOR: Por último sobre ese tema, presidente ¿qué le responde al gobernador de Tamaulipas, quien ayer dijo que es víctima de una campaña en su contra desde Palacio Nacional?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Tiene todo el derecho de manifestarse, de expresarse, de denunciar, es parte su libertad.\\nNada más decir que nosotros no tenemos un doble discurso, no somos hipócritas. La doctrina verdadera y a lo mejor la única de nuestros opositores, sobre todo de los conservadores, es la hipocresía, dicen una cosa y hacen otra, eso es la característica principal en todo.\\nAntes los del partido surgido del movimiento revolucionario cometían actos de corrupción y desde luego actuaban con autoritarismo, pero eran francos o, si se quiere, cínicos, eran corruptos cínicos; y los conservadores-conservadores son corruptos hipócritas.\\nDon Fidel Velázquez decía: ‘Soy charro, ¿y qué?’. Y estos se ensarapan.\\nEntonces, ahí les dejo de tarea de que escojan a unos o a otros, aunque ya ahora pues ya se unieron. Ahora que se votó, por ejemplo, lo de la reforma eléctrica, los representantes del partido de Adolfo López Mateos, que nacionalizó la industria eléctrica, votando por beneficiar a las empresas particulares, en contra de la Comisión Federal de Electricidad, de una empresa pública, que es la que permite desde hace años que tengamos energía eléctrica, la que electrificó todos los pueblos de México y en esta nueva etapa -porque la estamos rescatando- es la empresa que va a garantizar que no aumenten las tarifas de energía eléctrica en beneficio de los consumidores, para que el subsidio no se lo lleven las empresas extranjeras o particulares.\\nPero qué incongruencia que diputados del partido de Adolfo López Mateos voten a favor del debilitamiento, de la destrucción de una empresa como la Comisión Federal de Electricidad. Es un desconocimiento de la historia, es no tener convicciones ni tener principios, es buscar el cargo por el cargo, la lucha del poder por el poder. ¿Dónde están los ideales?, ¿dónde están los principios?, ¿dónde está el compromiso de defender los intereses del pueblo?\\nEso es lo que está sucediendo en el país, que son cosas también muy importantes, porque es un momento estelar en la historia de México y todos, ahí sí, todos los mexicanos están actuando con mucha responsabilidad, porque estamos llevando a cabo la transformación sin violencia.\\nINTERLOCUTOR: Presidente y una última, sobre violencia política. El día de ayer fue asesinado un aspirante a una alcaldía en Quintana Roo. Suman al menos 47 políticos asesinados en lo que va del proceso electoral, varios de ellos aspirantes a cargos públicos.\\n¿Considera que se está exacerbando esta violencia política?, ¿y qué va a hacer su gobierno para atajar esto?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Estamos tratando el caso.\\nCuando hay elecciones, se mete el crimen organizado y también la delincuencia de cuello blanco; se meten a financiar campañas y toman partido a favor de candidatos, porque quieren tener control en los municipios y en los estados.\\nAl principio, cuando empezó esto de la asociación delictuosa entre aspirantes o candidatos o políticos, aunque me cuesta trabajo decir políticos, porque la política es un noble oficio, la auténtica política, decía don Jesús Reyes Heroles: ‘Es tan limpia la política que ni los más sucios políticos han podido mancharla’, pero bueno, cuando comienza eso, esa vinculación, recibían dinero los candidatos para que, si ganaban en un ayuntamiento, les permitieran a las bandas de delincuentes poner al secretario de Seguridad Pública; luego fue escalando, ya no era al secretario de Seguridad Pública, daban el dinero también para que les entregaran el cargo de director de Obras Públicas; y luego ya de plano el presidente municipal a sus órdenes.\\nY va creciendo y va creciendo hasta que imponen presidentes municipales y los someten a que entreguen una cuota del presupuesto.\\nINTERLOCUTOR: Las participaciones.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, tenían la contabilidad de cuánto recibía el gobierno municipal y había que entregar una cuota porque, si no, los ajusticiaban.\\nAquí está el origen de muchas cosas, desde las campañas, por el afán de ganar a costa de lo que fuese, ganar por ganar.\\nEntonces, amenazaban a los candidatos opositores y había represalias, incluso asesinatos, luego cosas como que ganan y los mandaban a buscar a todos, el jefe de un grupo criminal podía reunir a 20, a 30 y todos tenían que ir y ahí les cantaba la cartilla.\\nEsto fue creciendo.\\nAdemás, como para sostener -y esto es muy importante- al régimen de corrupción nacional necesitaban los votos, se hacían acuerdos con estos grupos para rellenar las urnas, para falsificar las actas, entonces a cambio tenía que haber impunidad.\\nPor eso en algunos estados todavía no se puede resolver el problema de la violencia, de los homicidios, porque se metieron hasta abajo, en los municipios echaron raíces. Cada vez que hay una elección, hay este tipo de amenazas, por el predominio en zonas del narcotráfico.\\nNosotros estamos ya actuando para darle protección a todos los candidatos y para cuidar que no sean candidatos del crimen organizado ni de la delincuencia de cuello blanco.\\nPorque también no es nada más que actúe en una región de un estado o de una banda que actúa allá, no, acuérdense de lo que nos hicieron en el 2006, fue la cúpula del poder económico la que participó en el fraude electoral, las cámaras, el Consejo Coordinador Empresarial, la Coparmex, los directivos; ellos fueron los que pagaron la guerra sucia, la campaña en contra nuestra en los medios de comunicación. No estoy diciendo mentiras, ahí están las evidencias de los mensajes que pagaban en las televisoras en contra nuestra, estando prohibido.\\nEntonces, la carta de antier que dirijo a los gobernadores va en ese sentido. Primero, vamos a predicar con el ejemplo, que no se permita que se utilice el presupuesto público para favorecer a ningún candidato, que se denuncie si hay financiamiento de la delincuencia organizada o de la delincuencia de cuello blanco y desde luego que no se permita el fraude electoral en ninguna de sus manifestaciones. Ese es el pacto, el acuerdo por la democracia que estamos proponiendo.\\nY sí vamos a llevar a cabo, de acuerdo a consultas con los gobernadores, acciones para proteger a candidatos por esta situación. No es de que ‘yo quiero a este y tú, aunque seas el más popular, no vas a ser; es más, renuncia y, si no, atente a las consecuencias’.\\nCuando me tocó a mí la vida partidista nos hacían fraude y era evidente. Y a veces le decíamos a los candidatos nuestros que habían sido víctimas del fraude que había que presentar las denuncias; no las presentaban, porque los amenazaban. Todo esto lo estoy planteando para que se sepa, que se conozca bien.\\nY que también se sepa, se conozca que no vamos a dejar que estas prácticas mafiosas se arraiguen en el país o se sigan llevando a cabo y se afecte la vida de las personas y se limite la libertad, y pierdan la vida candidatos y pierdan la vida dirigentes independientes, y permitamos estos actos totalmente deleznables ¿no?\\nNo sé si tienen… Una vez te pedí, pero… Aquellas campañas que hicieron cuando el 2006.\\nJESÚS RAMÍREZ CUEVAS, COORDINADOR GENERAL DE COMUNICACIÓN SOCIAL Y VOCERO DE LA PRESIDENCIA: ¿Los videos?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, de Claudio X. González, Claudio X. González papá.\\nJESÚS RAMÍREZ CUEVAS: El peligro para México.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Peligro para México. ¿Tendrán algo?\\nJESÚS RAMÍREZ CUEVAS: Sí.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Porque no está de más recordarlo, no ha pasado mucho tiempo y era así, abierto. Y ahora el hijo de Claudio X González está metido en todo, es el que animó a que se unieran en contra de nosotros, también recoge dinero para campañas en contra nuestra.\\nUn día vamos a pasar aquí un documental. Van a decir los publicistas que estamos afectándonos a nosotros mismos, porque en sus reglas no hay que estar hablando de estos asuntos, y menos cuando es en contra de nosotros, pero es interesante que se conozca cómo manipulaban.\\nEse documental fue sobre el populismo, me acuerdo. No se atrevieron a transmitirlo en Televisa ni en Azteca, ni en otras televisoras; incluso pagaban para que…\\nEra una serie, creo que cuatro programas: uno era el populismo originario de Argentina, de Perón; luego el populismo en Cuba, creo; el populismo en Brasil, con Lula; el populismo en Venezuela, y remataban con el populismo en México, y hacían declaraciones intelectuales. Miren:\\n‘En el año de 2006 el Instituto Federal Electoral permitió la difusión del siguiente material en contra de uno de los candidatos a la Presidencia de México. Los comentarios quedan a juicio de la opinión pública.’\\nCorre.\\n(INICIA VIDEO)\\nVOZ HOMBRE: Vayamos preparándonos para la guerra asimétrica. ¡Socialismo o muerte!\\nVOZ HOMBRE: En México no necesitas morir para definir tu futuro, sólo tienes que votar. Ármate de valor y vota.\\nVOZ HOMBRE: López Obrador acepta la barbarie y que se rompa la ley. Esto dijo tras un linchamiento.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: La lección es: con las tradiciones del pueblo, con sus creencias, vale más no meterse.\\nVOZ HOMBRE: López Obrador es un peligro para México.\\n((FINALIZA VIDEO)\\n(INICIA VIDEO)\\nVOZ HOMBRE: ¿Un nuevo modelo económico? López Portillo hizo las mismas propuestas, el resultado fue una crisis de 10 años. Carlos Salinas también propuso lo mismo, el resultado fue la peor crisis en la historia de México.\\nHoy López Obrador las presenta como un nuevo modelo económico. Propuestas que endeudan, que provocan inflación y desempleo. Podrías perder la casa que compraste a crédito con tanto esfuerzo, podrías perder tu trabajo. No votes por otra crisis.\\n(FINALIZA VIDEO)\\n(INICIA VIDEO)\\nVOZ HOMBRE: Gratis el gas, la gasolina, el diésel, la luz, las Islas Marías como centro recreativo, los trenecitos bala para que se vayan de braceros. Ah, y se me acaba de ocurrir, que nadie pague impuestos.\\nVOZ HOMBRE: Muy bien, son un millón de millones pasaditos. ¿En efectivo o a crédito?\\nVOZ HOMBRE: No, pues endeuden, deuda, que pague el pueblo.\\nVOZ HOMBRE: El despilfarro de López Obrador lo pagaríamos muy caro todos los mexicanos. No votes por otra crisis.\\n(FINALIZA VIDEO)\\n(INICIA VIDEO)\\nVOZ HOMBRE Este es López Obrador.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Tengo tres cosas muy presentes: no mentir, no robar, no robar y no traicionar.\\nVOZ HOMBRE: Respecto al Fobaproa, López Obrador miente otra vez. En el 95, México entró en su peor crisis. Los diputados del PAN salvaron tus ahorros.\\nVOZ HOMBRE: No hizo nada, el culpable de la crisis fue Salinas por la irresponsable política de endeudamiento que López Obrador pretende de nuevo implantar. ¿Quieres otra crisis?\\n(FINALIZA VIDEO)\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Hasta ahí, pero faltaron algunos, donde se caían las bicicletas y se caían las bardas.\\nPues todo esto financiado por el sector empresarial de aquel entonces: Coparmex y el Consejo Coordinador Empresarial y todos.\\nLes fue bien, porque nos hacen el fraude y luego Calderón llega y les entrega Aeroméxico a algunos de estos. Había uno de Chihuahua, Barraza, que fue de los activos, junto con Claudio y otros más, a él le entregaron Aeroméxico, y a otros por esto.\\nAhora también ahí están queriendo hacer lo mismo, o sea, seguramente recogiendo dinero. Hay que estar muy pendientes.\\nEntonces, no sólo es la delincuencia organizada, es también la delincuencia de cuello blanco, que también está organizada: los que no pagan impuestos, los que se dedicaban a saquear, a robar.\\n¿Por qué Claudio X. González está en contra de la reforma eléctrica?\\nTodo tiene una explicación. Su papá, Claudio X. González, era asesor económico de Salinas. Todo esto lo digo porque, imagínense, hay muchos jóvenes que no habían nacido cuando eso, pero que ahora ya son ciudadanos. Entonces, era su asesor económico y siempre con mucha influencia, con todos los gobiernos.\\nÉl fue el que le recomendó a Peña que aumentara al doble la gasolina, Claudio X. González, está documentado; es más, doy la fuente, en el periódico Reforma en una entrevista, dijo que no había que estar pensando en otra forma de obtener ingresos, que lo más sencillo era aumentar al doble la gasolina y con eso se financiaba al gobierno, bolseando al pueblo, y le hizo caso el presidente Peña, porque de 10 pesos el litro pasó a 20, al doble. Entonces, mucha influencia.\\nViene lo de la reforma eléctrica, ¿y por qué se oponen?, porque desde que Claudio X González era asesor de Salinas y empiezan con la privatización de la industria eléctrica, ellos se vuelven socios y adquieren plantas de generación de energía eléctrica, cuando menos una planta grande en la Huasteca potosina, que desde hace muchos años le vende energía eléctrica a la Comisión Federal de Electricidad a precios elevadísimos.\\nHace como un año vendieron sus acciones, creo que a Iberdrola; entonces es comprensible de que estén en contra.\\nAcaban de formar una especie de consejo de defensores jurídicos en contra del gobierno para oponerse a todo jurídicamente y tienen ahí a exministros, a representantes de las organizaciones de abogados, todo un aparato. No es que les importe el que se cuide la riqueza cultural, arqueológica de México, porque están queriendo parar el aeropuerto por restos de mamut que se han encontrado.\\nVamos a tener…Ya se está construyendo un gran museo que va a ser algo extraordinario en la historia de la arqueología y de la cultura en el mundo con todos los restos de mamut que se están encontrando en Santa Lucía, pero eso no les importa, lo que quieren es frenar.\\nLo mismo el Tren Maya; eso, constantemente.\\nAhora que se aprueba la iniciativa de fortalecer a la Comisión Federal de Electricidad, ya estaban hablando que van a presentar recursos impugnándola en el Poder Judicial. Pues están en su derecho, pero deberían ellos de darlo a conocer así, de manera abierta. Y además yo no soy nadie para estarles dando consejos, eso sí ya es el colmo, pero que hablen claro.\\nAhora con la simulación sobre el feminismo empiezo a escuchar: ‘Rompe el pacto, rompe el pacto, rompe el pacto’. Les digo sinceramente, y no miento, me enteré de lo que era eso hace cinco días, porque mi esposa me dijo. Le digo: Oye, ¿qué es esto de ‘rompe el pacto’?, explícame; y ya me dijo: ‘Rompe el pacto patriarcal, o sea, deja de estar apoyando a los hombres’.\\nPero yo, cuando se habla de ‘rompe el pacto’, pues ya lo estoy rompiendo: el llamado Pacto por México, que no fue más que pacto contra México; o el pacto del silencio que establecieron los que reprimieron y desaparecieron a los jóvenes de Ayotzinapa, pacto de silencio; pero el otro pacto no.\\n¿Y saben qué sucede?\\nQue son expresiones exportadas… importadas, expresiones importadas, o sea, copias. ¿Qué tenemos nosotros que ver con eso si nosotros somos respetuosos de las mujeres, de todos los seres humanos? Pero también en eso se monta el conservadurismo.\\nEl caso de Guerrero, con Félix, como es candidato, toda la oposición. Y lo dije desde el principio con mucha claridad: Que resuelvan los guerrerenses, las mujeres, los hombres de Guerrero y la ley, pero ¿por qué hacer mediático en todos los programas, todos los medios -con excepciones- acusándonos de estar en contra de las mujeres? Pues no. Nosotros estamos a favor de los derechos de las mujeres, baste decir que la mayoría de los servidores públicos del más alto nivel son mujeres y venimos de un movimiento donde siempre hemos respetado a las mujeres. ¿De cuándo acá los conservadores se vuelven feministas?\\nEntonces, todo esto es interesante, por el papel de los medios de información, o sea, de cómo quieren afectarnos, los ataques constantes, la desinformación, la manipulación.\\nYo soy humanista y respeto por eso el feminismo, y no somos iguales a los conservadores, no tengo ningún problema de consciencia.\\nEntonces, era contestarte esto.\\nSara.\\nPREGUNTA: Gracias. Buenos días, presidente.\\nPreguntarle sobre el tema de la Auditoría. Si con esto que pasó del aeropuerto, para usted desacredita todo el trabajo que hizo este año la Auditoría de la cuenta pública del 2019.\\nHubo muchas observaciones sobre algunos otros programas sociales. Si no confía en estos datos, en estas auditorías que se dieron a conocer.\\nY justo hay voces por eso que dicen que el auditor debería dejar su cargo, porque está desacreditada después de lo que ocurrió.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Pues hay una parte de la carta. ¿Por qué no la ponen?, que contesta lo que tú planteas. Abajo, los últimos párrafos, esto. Ya se retractaron, hablando de que hubo una mala proyección del cálculo. Sí considero que hubo mala fe, hubo motivaciones políticas.\\nEs que también esto es entendible. No defiendo a nadie, pero aquí nos pasa, estamos en un proceso de transición, lo viejo no acaba de morir y lo nuevo no acaba de nacer.\\nHay veces que tenemos una reunión, fíjense, de seguridad, de 6:00 a 7:00 de la mañana y hablamos sobre un tema, y al día siguiente Rock o Riva Palacio describen lo que pasó. Una filtración. Imagínense, el que da información de reuniones de seguridad.\\nPorque son 36 años de predominio de la política económica neoliberal. Repito, el porfiriato fueron 34 años y todavía sigue existiendo, ya no es predominante, pero ahí está. El pensamiento conservador nunca muere.\\nCuando hubo el acto de justicia en Querétaro y se expulsa a los extranjeros, triunfa la República, se pensó: ‘Ya se alejó la amenaza de las invasiones, está muy difícil que el partido conservador vuelva por sus fueros’. Pues no tardó y regresó con Porfirio Díaz.\\nEntonces, existe esta situación en todas las instituciones, y más cuando se trata de un poder independiente, como es la Cámara de Diputados.\\nImagínense cuánta gente de esa institución viene de tiempo atrás. Si nosotros todavía contamos con la participación de técnicos que vienen también del periodo neoliberal y es muy difícil estar haciéndoles entender que entren en razón, porque aprendieron esa fórmula; y es mucho tiempo el que duró, estamos hablando de una generación completa.\\nImagínense a un tecnócrata: ‘¿Cómo que no se va a rescatar a los de arriba?, ¿cómo que no se va a pedir crédito para apoyar a la industria -porque así lo disfrazaban- y mantener el empleo?’ Pues no, se va a rescatar a los de abajo, pero eso no se los enseñaron, ni en el Tecnológico de Monterrey ni en el ITAM, es más, ni en la UNAM.\\nEntonces, estamos en un terreno del todo nuevo, es un proceso, entonces ahí va a ir poco a poco.\\nEntonces, la Auditoría sin duda debe de tener auditores, abogados, funcionarios, que vienen de tiempo atrás y que también deben de pertenecer o simpatizar con la oposición. Esto es, diría yo, natural.\\nEntonces, por eso sin cuidado de lo más elemental se atreven a dar un informe totalmente tendencioso y falso.\\nEntonces ¿quién va a aclarar?\\nPues la Cámara de Diputados.\\nINTERLOCUTORA: ¿No necesariamente tuvo que ser el auditor el responsable de esta falsedad?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Yo no puedo señalar a nadie, nada más decir cómo están funcionando las instituciones.\\nYo mismo tengo que andar a las vivas de quienes están trabajando en el gobierno para que no hagan cosas indebidas, porque no es la agenda del servidor público, ni siquiera la agenda de la secretaría o de la institución de que se trate, es la agenda del gobierno de la República.\\nEntonces, antes cada quien actuaba como pensaba, de acuerdo a sus intereses y de conformidad también a sus fobias; y ahora es orden.\\nEntonces, eso puede estar pasando en esta institución, por eso es mejor que se haga la investigación y se aclare para satisfacción de todos.\\nClaro, ya nos hicieron un daño. Es lo mismo de la máxima del hampa del periodismo, que la calumnia, cuando no mancha, tizna. Ya el golpe… Imagínense cuánto tiempo le dio la televisión. A mí me gustaría… A ver si un día tenemos cómo lo manejó Televisa o cómo lo manejó Azteca o Imagen, también para no hablar sólo de los periódicos o la radio; sería bueno que mañana, sobre esto, cómo lo manejaron los conductores de radio, no sólo Loret de Mola, sino otros, para abrir el abanico; y en la televisión los ¿cómo se llaman?, sí, los noticieros.\\nEntonces, a ver, me acordaba, pero en el sentido contrario, de cuando el presidente Zedillo dio a conocer que el rescate bancario iba a costar 180 mil millones de pesos y así de entrada costó un billón, y hasta ahora son tres billones, o sea, que se equivocó por muy poquito, casi-casi le atina, de 180 mil millones de pesos a tres billones; acá de 330 mil, que supuestamente costó en no construir el aeropuerto, a 110 mil. Entonces, sí está considerable la diferencia.\\nPor eso es que, a ver, ¿están mal las cuentas o hubo mala fe?, porque si la diferencia fuesen cinco mil millones, sí, pero aquí estamos hablando de una diferencia…\\nINTERLOCUTORA: El triple.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, del triple, más de 200 mil millones de diferencia.\\nA ver, le voy a decir algo a los conservadores. Ya ven que hay en la red un diablito que dice: ‘Diles que te vas a reelegir’. Bueno, pero ahora el diablito me está diciendo ahora: ‘Con los ahorros, a ver, la polémica buena, con los ahorros del aeropuerto casi vamos a financiar el Tren Maya’.\\nComo decía un periodista extraordinario, don Trino Malpica, mi paisano: ‘Ahí queda eso’. Ya.\\n¿Qué más?\\nINTERLOCUTORA: Presidente y de la reforma eléctrica, el presidente del Consejo Coordinador Empresarial, Carlos Salazar, dice que la energía se podría encarecer porque ellos, las empresas privadas, van a generar energía más cara y se va a trasladar el precio a los consumidores, que además va a haber una ola de amparos, en fin, que se van a presentar por esta ley. ¿Qué les garantiza usted a los mexicanos?\\nUsted ha dicho que, por el contrario, va a bajar la energía con esta reforma. Entonces, si buscaría algún tipo de arreglo con las empresas o se irían a los tribunales.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Mire, Sara, nada más para aclarar, porque lo que más cuido es ser consecuente. Yo no he dicho que se va a bajar el precio de la energía eléctrica.\\nINTERLOCUTORA: Bueno, que se iba a conservar y que se podría bajar con esta reforma.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Ah, eso sí, eso sí, que mínimo mi compromiso es conservar el precio en términos reales, no va a aumentar, lo que pasaba en otros sexenios, no va a haber gasolinazos ni va a aumentar en términos reales el precio de la energía eléctrica, ese es mi compromiso, no bajar, porque entonces van a decir: ‘Usted no cumplió’.\\nSi nos va bien, que yo espero, entonces en su momento podríamos decir: Se redujo. Por ejemplo, durante la pandemia bajó el precio de la gasolina, no se mantuvo, bajó, pero el compromiso es que no aumente en términos reales, ese es mi compromiso y lo voy a sostener.\\n¿Qué le digo al presidente del Consejo Coordinador Empresarial?\\nQue nos ayude a convencer a los que están recibiendo subsidio y no les corresponde: las grandes corporaciones, a las cadenas de tiendas comerciales que están consumiendo energía eléctrica subsidiada, que el subsidio se le tiene que dar al consumidor doméstico, que él sabe a lo que me refiero. Que era muy injusto, sigue siendo muy injusto que se proteja a los de arriba y se deje desamparados a los de abajo.\\nPara que nosotros podamos garantizar que no aumente el precio de la luz necesitamos poner orden, acabar con la corrupción, acabar con los privilegios.\\n¿Qué más corrupción, qué más privilegios pueden exhibirse?, que es como el cuento del rey va desnudo, ¿qué más quieren?\\nQue una de estas empresas beneficiadas, Iberdrola, se llevó a trabajar por el trato recibido a la secretaria de Energía; porque no estoy hablando de que se llevó a trabajar al secretario del Medio Ambiente, ni siquiera al secretario de Hacienda, no, a la secretaria de Energía, la cabeza de sector, del sector energético, la que tiene que ver con la industria eléctrica, se la llevó a trabajar a su empresa, Iberdrola, de empleada, después de que había estado de secretaria de Energía; pero, no conforme con eso, se llevaron de consejero de Iberdrola al expresidente Calderón.\\nEs como cuando Zedillo entrega los ferrocarriles, termina y se va a trabajar a una empresa ferrocarrilera que se benefició con la venta o entrega de los ferrocarriles nacionales. A esa empresa le vendieron, la concesionaron como 10 mil kilómetros de vías férreas con la privatización, y cuando acabaron con los trenes de pasajeros. O sea, es una vergüenza nacional.\\nEs como si yo termino y me voy a trabajar con Odebrecht o me voy a trabajar con cualquier empresa.\\n¿Por qué lo hicieron?, ¿porque son muy buenos profesionales?, ¿porque necesitaban profesionales como ellos? No, era para presumir que ellos tenían muchas influencias.\\nEl que llevó a cabo lo del Fobaproa, el que convirtió las deudas privadas de banqueros en deuda pública que benefició a los bancos, se fue a trabajar a uno de esos bancos a Citi Group, que era antes Banco Nacional de México. Un descaro, una falta de respeto al pueblo, a la nación.\\nEntonces, no es que vayan a dejar de hacer negocio, van a seguir haciendo negocios.\\nAntes de que escribiera su libro sobre el desarrollo estabilizador, don Antonio Ortiz Mena, cuando estaba todavía de director del BID escribió un ensayo explicando cómo había manejado la Secretaría de Hacienda durante dos sexenios, con el presidente López Mateos y con el presidente Díaz Ordaz. En esos dos sexenios la economía creció a una tasa promedio anual del seis por ciento, pero, lo más importante: que hubo ese crecimiento sin que el país se endeudara, sin inflación y sin devaluación de la moneda.\\nEntonces, en ese texto… Porque él es de los que inicia todo el desarrollo de Cancún desde Hacienda, apoyándose en la banca de desarrollo, con otro enfoque, la banca de desarrollo para impulsar proyectos en beneficio de México: el campo, la industria eléctrica, a él también le correspondió lo de la nacionalización de la industria eléctrica para electrificar todos los pueblos, la construcción de las presas, las hidroeléctricas y el desarrollo turístico, cuando nadie pensaba en el potencial que tenía la Rivera Maya para el turismo.\\nBueno, en ese texto habla de que los empresarios tienen que hacer negocio, pero dice, con ganancias razonables. Claro que tiene que haber negocios, pero ganancias justas, vamos a decir, razonables.\\nAquí no era así en los últimos tiempos. Era saqueo, robo, contratos leoninos. Imagínense eso de los reclusorios, lo que significó esos contratos, que se tiene que pagar 16 mil millones de pesos por ocho reclusorios que se privatizaron, 16 mil millones de pesos al año por ocho reclusorios.\\n¿Quién construyó los reclusorios?, ¿quién se beneficia con el compromiso que tiene el gobierno de pagar por el 100 por ciento de reclusos, aunque sólo se tenga cubierto el 20 por ciento? Hay que pagar el 100 por ciento, así está en el contrato y que al final, a los 20, 25 años, el reclusorio no pasa al gobierno, sigue siendo de la empresa.\\n¿Quién firmó esos contratos leoninos? ¿Y quiénes se beneficiaron?\\nBueno, ya sabemos, el cuñado de Carlos Salinas y otros. Entonces, ¿qué ganancia razonable es ese negocio?, ¿dónde está la ganancia razonable? No, es un atraco, eso es influyentismo, eso es corrupción.\\n¿Quién estaba de subsecretario de Hacienda cuando entregan esos contratos?\\nTambién el cuñado de este señor Gerard, que al mismo tiempo es cuñado de Salinas. Pues eso es lo que prevalecía.\\nEntonces, regresando a lo de la Auditoría, que se investigue, que se haga una revisión; es más, existe una comisión en la Cámara de Diputados con ese propósito, de esa comisión depende la Auditoría de la Federación.\\n¿Qué otra cosa, Sara?\\nINTERLOCUTORA: Presidente, tiene razón, no dijo que con esta reforma bajarían los precios de la luz, lo dijo más bien en la campaña. Entiendo que han cambiado ahora las circunstancias.\\nNada más preguntarle sobre Pemex. Ya ve que hace unos días se dio a conocer el decreto para que se le disminuya la carga fiscal. Yo quisiera saber si además va a haber una inyección de capital líquido a Pemex como se ha publicado.\\nGracias.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí.\\nINTERLOCUTORA: ¿Y de cuánto sería?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: A Pemex se le están quitando los impuestos, se le están reduciendo impuestos para fortalecer a Pemex, igual que a la Comisión Federal de Electricidad, y se le va a ayudar para que no le falten recursos para las labores de exploración y de producción de campos petroleros.\\nTambién aclarar que nuestra política no va a consistir en sólo extraer más petróleo crudo, porque tenemos que cuidar la herencia para las nuevas generaciones. No extraer y extraer petróleo crudo y vender petróleo crudo.\\nVamos a mantener una política para que haya reposición de las reservas, que no se agoten nuestras reservas y por eso también vamos a procurar producir petróleo crudo para la refinación; que, en vez de vender el petróleo crudo, lo refinemos en el país y se produzcan las gasolinas y no tengamos que comprar gasolinas ni diésel, que no tengamos que importar.\\nMe da mucho gusto de que ayer el presidente Biden señaló, o sus asesores, que está a punto de dar a conocer un plan para que Estados Unidos sea autosuficiente en alimentos, en energía y, en vez de cerrarse, está planteando que haya acuerdos, imagino que con nosotros y otros países, para garantizar su abasto.\\nHablaban de que tienen déficit en producción en automóviles, en equipos de computación y en otras ramas, en otros productos, entonces es importante que ellos estén pensando en la autosuficiencia.\\nNosotros tenemos que ir hacia allá, seguir caminando hacia allá, que podamos producir lo que consumimos; y en el caso del sector energético esa es la política, que se produzca en México la gasolina, el diésel, por eso la construcción de la nueva refinería, la rehabilitación de las nuevas, de las refinerías que ya existían y otras actividades.\\nYo tengo como propósito que en el 23 vamos a dejar de comprar las gasolinas, a finales del 23 ya vamos a ser autosuficientes. Por eso estamos trabajando en ese sentido.\\nINTERLOCUTORA: Pero sí van a inyectar…\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, sí.\\nINTERLOCUTORA: ¿Cuánto sería?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Pues ahora con la disminución de impuestos, alrededor de 100 mil millones, aparte, estamos esperando también lo que nos va a entregar el Banco de México de remanentes.\\nINTERLOCUTOR: ¿Cuánto es?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Se está haciendo la cuenta. Eso lo entregan en abril y se va a utilizar para pagar deuda, ese dinero.\\nAh, perdón, Shaila.\\nPREGUNTA: Hola, presidente. Buenos días. Shaila Rosagel, corresponsal de Grupo Healy, El Imparcial, de Sonora; La Crónica, de Mexicali; Frontera, de Tijuana.\\nPresidente, el canciller Marcelo Ebrard dijo la vez pasada que estuvo aquí, que hay una preocupación porque la iniciativa Covax no ha cumplido con la entrega de dosis, son 51.5 millones de dosis las que están comprometidas con México.\\nEntonces, preguntarle si, en caso de que no se cumpla con esta entrega de vacunas, si hay algún Plan B para suplir estas dosis.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Tenemos vacunas ya contratadas suficientes.\\nTe referías a…\\nINTERLOCUTORA: A las de Covax, las que dijo el canciller que no han entregado.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, sí. Vamos a esperar, quedaron en decirnos en esta semana cuándo nos entregan.\\nNo se suspende el contrato, nada más es que estamos solicitando el calendario de entrega para nosotros tener en definitiva nuestro programa nacional ya de vacunación. Pero no nos vamos a parar, eso sí es importante decir.\\n¿No presentaron ayer el…? A ver, ¿por qué no lo pones?, porque esto es muy importante que se conozca. De lo que ya tenemos seguro, lo que nos va a llegar y hasta dónde vamos a avanzar.\\nQuiero aprovechar para agradecerle al embajador de China en México por su apoyo, porque están por llegar 800 mil vacunas más de China. Hablamos de un millón de vacunas, llegaron 200 mil y ahora van a llegar, creo que mañana, o están por llegar 200 mil, aquí deben de estar.\\nEste es el programa. Tenemos pensando terminar febrero con 3.3 millones. Ya estamos incluyendo Covax, porque fue lo que mínimo dijeron nos iban a entregar, incluso puede ser más de lo que tenemos contratado con ellos; pero si es así, vamos a llegar a 23 millones, eso es lo que tenemos.\\nY en abril serían 33 millones y en mayo pasaríamos a 46 millones. Si esto resulta, aquí a finales de marzo, que era lo que plantee desde el principio, tendríamos vacunados cuando menos con una primera dosis a todos los adultos mayores y a los médicos y enfermeras, trabajadores del sector salud de los hospitales COVID.\\nPero estamos haciendo gestiones para ampliar, sobre todo en estos meses, que es cuando hay menos vacunas, y además que es notorio el acaparamiento.\\n¿Lo vemos, el acaparamiento?, ¿no tienes ahí la distribución de vacunas en el mundo?\\nYa aumentó como a 100 países, 94, sí, pero sigue quedando casi la mitad sin una dosis de los países del mundo. Es ese.\\nMiren nada más: Estados Unidos y China, más de 100 millones; hasta aquí, hasta Rusia, se llevan el 80 por ciento de toda la producción y de ahí baja, nosotros estamos en el 19 lugar, hasta Canadá y Grecia, y Dinamarca, pero América Latina muy maltratada, Costa Rica va muy bien porque es poca su población, pero de todas maneras, 1.1 de vacunados.\\nBájale. Panamá va bien, aunque lleva el 1.4; acaba de empezar Colombia; El Salvador acaba de entrar, ya lleva seis mil vacunas.\\nA ver. ¿Hasta ahí quedó? Ya no hay de América Latina. Ah, sí, Trinidad y Tobago, 440, el Caribe.\\nPero son 94 de casi 200 países. Entonces, vamos a seguir insistiendo que distribuyan.\\nY hay casos en donde las tienen congeladas, guardadas, o sea, es muy probable que la producción sea mayor, pero están ahí congeladas, que las van a necesitar hasta en un mes, pero las tienen, o sea, o que van a poder aplicarlas en un mes y ahí las tienen, que deberían de resolver mejor esta situación.\\nMuy bien.\\nINTERLOCUTORA: Presidente, una segunda pregunta. Desde el arranque de 2021, Baja California y en específico Tijuana han registrado altos índices en el homicidio doloso. Tijuana forma parte de este programa del gobierno federal para combatir la violencia en 15 municipios.\\nAhora en su visita que realizó a Tijuana recientemente, preguntarle si tuvo la oportunidad de comentar los datos recientes sobre Tijuana y revisar la estrategia, ver cómo está funcionando la estrategia ahí en Tijuana.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, sobre eso trató la reunión que tuvimos en Tijuana en la inauguración del cuartel de la Guardia Nacional, a eso fuimos, y a reforzar actividades porque, en efecto, Tijuana es uno de los municipios con más homicidios en el país, como otros.\\nEsto se informó el día 20 de este mes y estamos trabajando con ese propósito, de garantizar la tranquilidad y la paz ahí en Tijuana.\\nINTERLOCUTORA: ¿Hay alguna meta, presidente, que se hayan trazado en Tijuana precisamente en esta visita para reducir el índice de homicidios?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, más trabajo coordinado, más elementos de la Guardia Nacional, eso fue lo que se acordó y continuar trabajando todos los días, todos los días, en Tijuana y en todo el país.\\nINTERLOCUTORA: ¿Cuántos elementos más serían enviados de la Guardia Nacional?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: No tengo el dato, pero debemos de tener ya alrededor de dos mil.\\nA ver, ¿por qué no…? Del informe del general Bucio, de la Guardia, del día 20, hay una distribución de elementos por estado.\\nINTERLOCUTORA: Sobre estos elementos que hay ¿se van a enviar más a Tijuana?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, se están incluso construyendo. Ya son, creo que siete cuarteles nuevos, ahorita los vemos.\\nSí, pero estos son los inspectores. Ah, sí, pero aquí están los efectivos. A ver si está Baja California. Mira, no me equivoqué, dos mil 99 elementos.\\nYa hay estados en donde se tienen más elementos de la Guardia Nacional que policías estatales, y esto lo hemos hecho en muy poco tiempo, en año y medio.\\nY ya tenemos terminados 140 cuarteles y estamos trabajando en 100 más; vamos a tener alrededor de 240 cuarteles en toda la República. Y van a aumentar los elementos, no van a ser esos 98, sino vamos a llegar a 140 mil elementos de la Guardia. Entonces, esta es la estrategia, reforzar.\\nA ver si no tenemos el número de cuarteles para Baja California, los nuevos, aparte del que inauguramos en Tijuana, ya inauguramos o está por terminarse, porque no voy a todas las inauguraciones, pero el de San Quintín ya está a punto.\\nPero hay más, aquí nada más está este. Sí, pero aparecen dos. Ah, no, cinco y uno, sí, sí, cinco construidos y uno en proceso.\\nJESÚS RAMÍREZ CUEVAS: Fue uno del 19 y cinco en el…\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Ah, de acuerdo, seis, seis en Baja California.\\nINTERLOCUTORA: Presidente, sobre un tema de Sonora, los transportistas del país tuvieron una reunión virtual antier para hablar sobre los bloqueos que todavía mantiene la tribu yaqui y pedirle al gobierno federal que se llegue a un acuerdo con la tribu.\\nEllos dicen que por las carreteras de Sonora circulan ocho mil camiones de carga al mes y cada unidad aporta a los manifestantes que están bloqueando la carretera federal alrededor de 600 pesos.\\nPreguntarle: ¿qué se está haciendo ahorita para detener este bloqueo?, que entiendo que es por una parte nada más de la tribu.\\n¿Y qué avances tienen en las mesas de diálogo?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Se está avanzando en la negociación, en los diálogos, en los acuerdos con los pueblos yaquis.\\nHay, como sucede en todo, hay inconformes. Todos los gobernadores apoyan el que se llegue a un acuerdo, pero hay una disidencia que no acepta acuerdos; sin embargo, se está hablando con ellos y yo creo que pronto vamos a lograr el acuerdo. Lo está viendo Adelfo, que es el de pueblos indígenas.\\nTenemos un compromiso con los yaquis que se va a cumplir, ya se está trabajando allá con ellos constantemente, ya se está viendo el problema agrario, el problema del agua, lo del desarrollo de sus pueblos, de los pueblos yaquis.\\nVamos a visitarlos para llevar a cabo, en el marco de la conmemoración de la Independencia nacional, un acto en los pueblos yaquis, vamos a llevar a cabo en uno de los pueblos un acto, como el de ayer de Iguala. Este acto va a ser para ofrecerles disculpas, para pedir perdón por toda la represión que padecieron sus antepasados, el exterminio, porque fueron asesinados miles, las deportaciones de yaquis; todo esto, en el porfiriato, para trabajar como esclavos en las haciendas henequeneras de Yucatán, en las plantaciones de caña del sureste. Una barbaridad, una especie de segunda conquista.\\nEntonces, ahora que estamos conmemorando los 200 años de nuestra independencia, pues lo que queremos y no aceptaron, pero es un acto de conciencia y de voluntad, no es nada obligatorio, nada por la fuerza, le pedimos al rey de España que se ofrecieran disculpas a los pueblos originarios; ellos hasta ahora no han respondido.\\nHa habido cuestionamientos a nuestro gobierno por pedirles esto, que era buscar una auténtica reconciliación a partir de ofrecer disculpas por el autoritarismo.\\nNo podemos estar pidiendo nosotros que los gobiernos extranjeros u otras instancias del exterior se disculpen si nosotros no hacemos lo mismo porque, a partir de que logra la independencia política de México, continúan también prácticas racistas, clasistas, discriminatorias y, lo peor, la represión, como sucedió con los yaquis, como sucedió con los mayas, con los mayos y con todos los pueblos originarios, la manera en que fueron despojados de sus tierras, bueno, el racismo que existe hasta la fecha.\\nVamos a ir allá a esta ceremonia. Pero también no se trata sólo de pedir perdón, sino de reivindicarlos, de apoyarlos, porque son los más pobres de Sonora, siguen estando marginados. Es ayudarlos en todo lo que podamos.\\nHubo un decreto para que recuperaran sus tierras durante el gobierno del general Lázaro Cárdenas y luego ese decreto no fue obedecido, se les recuperaron parcialmente sus tierras, y además no se respetó la resolución presidencial del presidente Cárdenas, ni en lo que tiene que ver con la tierra ni en lo que tiene que ver con el agua.\\nEstamos buscando hacer justicia, como lo tenemos que hacer con todos los pueblos originarios indígenas y afromexicanos.\\nINTERLOCUTORA: Presidente ¿cuánto tiempo (inaudible) haber una negociación con este grupo?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Voy, ahora que lo estás planteando, voy a pedir un informe de cómo va específicamente lo de la carretera a Adelfo y le voy a pedir también a Ricardo Mejía que me informe sobre esto, y que se apuren para que se llegue a un acuerdo.\\nY que no se provoquen enfrentamientos, que se evite la violencia, que se llegue a un acuerdo, porque sí, esto ha exacerbado las cosas, ha calentado mucho los ánimos ahí en Obregón, en toda esta región de Sonora y tenemos que buscar soluciones pacíficas, pero también efectivas, o sea, que resuelvan el problema. Diálogo con compromisos.\\nINTERLOCUTORA: Ya hubo también conflictos de los traileros y ya murió un muchacho de la tribu.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, sí, hace unos días, y eso es lo que queremos evitar y estamos en eso, porque estamos limpiando para que no estén tomadas casetas, porque era un negocio que tenían.\\nY ya se han ido liberando casetas en Nayarit, en Sinaloa, falta Sonora, porque queremos que sea a través de un diálogo para evitar la confrontación. No hay que olvidar que la política, entre otras cosas, se inventó para evitar la confrontación, para evitar la guerra. Por eso, cuando declaran la guerra al narcotráfico, la política se va al carajo.\\nPREGUNTA: Presidente, muy buenos días. Amir Ibrahim, de Quintanaroo.mx.\\nSobre el turismo, mi estado es un estado que depende completamente del turismo. Los trabajadores del turismo los steward, recamaristas, toda la gente que trabaja que es casi toda, los empresarios están muy preocupados por la reactivación del turismo en nuestro estado, yo me imagino que en México también.\\nQuisiera preguntarle: ¿cuáles son las estrategias después de sufrir este 2020 la pandemia para levantar y competir en el sector turístico en México específicamente en Quintana Roo?\\n¿Y qué se ha hecho también?, ya que, cuando llegó, las embajadas se supone que tendrían que hacer la promoción turística. Si tiene algún informe de esa promoción que se ha realizado en los consulados.\\n¿Y cuáles son las estrategias desde el gobierno federal para apoyar al turismo en todo el país y específicamente a Quintana Roo?\\nGracias, presidente.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Bueno, en la circunstancia actual lo que va a ayudar mucho al turismo, en especial a Cancún y a toda la región que tiene que ver con el Caribe, que es una de las zonas más bellas del mundo, va a ayudar mucho lo de la vacunación, porque en el caso de Quintana Roo va bien el combate a la pandemia y esto se sabe.\\nINTERLOCUTOR: Estamos en amarillo ahorita.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí. En todo el mundo, y vamos a vacunar pronto y yo espero que en tres meses, ese es mi pronóstico, tres meses, a mediados de año inicie ya la recuperación de la actividad turística en Cancún, en Los Cabos, en Vallarta y en Nayarit y en otros sitios, porque va a coincidir con el avance en la vacunación de Estados Unidos.\\nAhora con la pandemia la recomendación que se está haciendo es que se viaje poco y que sean viajes cortos, entonces todo el turismo de Estados Unidos, de Canadá va a preferir a México, esto lo están proyectando o lo consideran quienes manejan esta actividad; de modo que nosotros nos vamos a apurar para vacunar.\\nY al mediano plazo lo que va también a ayudar mucho es que se va a construir el aeropuerto internacional de Tulum. Es un compromiso, y lo vamos a hacer pronto.\\nINTERLOCUTOR: ¿Habrá fecha aproximada de eso?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: A más tardar lo vamos a terminar en el 2023, por eso hablo del mediano plazo. En 2023 inauguramos el Tren Maya y el aeropuerto de Tulum, entonces eso va a significar un impulso al turismo muy importante en Quintana Roo. Entonces, yo ya veo la luz al final del túnel.\\nCuando la crisis del sargazo, había pesimismo. Yo fui a Cancún y dije: Lo vamos a resolver.\\nINTERLOCUTOR: Sí nos pegó duro el sargazo.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Pero lo resolvimos, porque le pedimos al almirante Ojeda y a la Secretaría de Marina que se encargara, junto con hoteleros y prestadores de servicio, para resolver el problema y se resolvió. Entonces, ahora vamos a salir adelante.\\nYo voy a estar allá en marzo, voy a estar en Quintana Roo, porque quiero hablar con los hoteleros porque vamos a construir el tramo de Cancún a Tulum del Tren Maya.\\nDesde luego es todo el tren, es Palenque, Campeche, Yucatán, en particular Mérida, Cancún, Tulum.\\nINTERLOCUTOR: El que llega hasta Chetumal, ¿no?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Chetumal, Escárcega y de nuevo Palenque, son mil 500 kilómetros. Pero el tramo, que son 120 kilómetros, Tulum-Cancún, de 120 kilómetros, es el tramo de menos extensión es complicado, porque vamos a hacer el tren en el derecho de vía de la actual carretera.\\nINTERLOCUTOR: En medio de la carretera.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: En medio. Entonces, voy a ir para explicar de cómo lo vamos a hacer lo más pronto posible.\\nINTERLOCUTOR: ¿Tiene fecha aproximada de esta otra de cuándo termine ese tramo?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Lo queremos hacer en un año, a más tardar en un año.\\nPor eso son dos subtramos, vamos a decir. De los 120, decidimos hacer un tramo que llamamos Cancún Sur, que es de Tulum a Playa del Carmen, que ahí no hay tanto problema, no hay tantas instalaciones turísticas, hoteles y demás. Ese tramo ya se licitó y va a estar a cargo de Grupo México.\\nINTERLOCUTOR: La constructora.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí. Y le estamos haciendo la recomendación que -son como 22, 25 kilómetros que les corresponde- que se apliquen.\\nY el otro tramo que es el más difícil -porque no queremos causar molestias para no afectar el turismo y hacerlo lo más pronto posible- lo va a construir el Ejército, los ingenieros militares, van a construir 22 kilómetros.\\nINTERLOCUTOR: ¿El de Playa a Cancún?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: El de Playa a Cancún.\\nINTERLOCUTOR: ¿Va a llegar al aeropuerto, presidente?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Al aeropuerto de Cancún.\\nINTERLOCUTOR: ¿Va a haber parada en el aeropuerto?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Ahí, ahí va a ser la terminal.\\nINTERLOCUTOR: ¿Y otra en el centro de la ciudad?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Ese es un ramal del aeropuerto de Cancún al centro. Pero eso lo estamos analizando, porque tenemos que terminar a tiempo.\\nYa también estamos por resolver lo de la adquisición de los trenes, porque no es de un día para otro que se compran estos trenes, además son distintos trenes, porque va a haber trenes para carga, trenes para pasajeros, desde luego modernos, y trenes para el turismo.\\nINTERLOCUTOR: Se había dicho del taller de compostura, que iba a estar en Chetumal. ¿Es correcta esa información?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Se está por resolver si es en Cancún, si es en Chetumal o es en Escárcega, o sea, estamos viendo todo esto.\\nPero sí comentarte que va a ser el Ejército, los ingenieros militares los que van a trabajar, porque vamos a hacer ese tramo en un año a más tardar.\\nINTERLOCUTOR: 2020.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, para no afectar. 2021, 2021-2022.\\nSi empezamos en marzo, que es lo que quiero, a marzo del año próximo.\\nPREGUNTA: ¿Con los recursos legales les dará tiempo, presidente? Porque ya ve que han estado interponiendo amparos.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí, pero no tienen sustento.\\nPREGUNTA: (Inaudible).\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: No, no hay, la gente está apoyando el Tren Maya. Son estos, los Claudios.\\n¿Cómo se llama la asociación en contra de la democracia, de la corrupción?, ¿cómo es? Mexicanos a Favor de la Corrupción, esos son.\\nINTERLOCUTOR: ¿En este tramo del que estamos hablando no ha habido…?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: No, porque además va por el derecho de vía. Desde luego van a haber impugnaciones de todo.\\nEs como cuando hablé, y no por eso vamos a dejar de revisar, las llamadas instituciones autónomas, que nacieron durante el periodo neoliberal como hongos después de la lluvia. Hay infinidad de aparatos burocráticos, los llamados autónomos, la sociedad civil, que se puso de moda, porque necesitaban legalizar la corrupción y los usaron para legitimar el modelo neoliberal de privatización, de robo. Entonces, fueron creando, para todo, organismos autónomos.\\nYo nada más les recuerdo, para que se dimensione, que son estos organismos autónomos, porque dicen: ‘Es de la sociedad civil’. No, no son de la sociedad civil, son de los grupos de intereses creados. Organismos autónomos no. Si es de comunicaciones, tiene que ver con las televisoras, tiene que ver con las telefonías.\\n¿De quiénes son los organismos autónomos?\\nDe esas empresas.\\nSon independientes del pueblo, no del poder. Así se fueron creando todos estos organismos y tenemos que hacer una revisión, porque cuesta mucho mantenerlos, ganan por hacer el trabajo de alcahuetes hasta 300 mil, 400 mil pesos mensuales.\\nEntonces, se molestan mucho porque plantee, dicen: ‘No, se va a afectar a la sociedad civil’. No, a la sociedad civil antes se le llamaba pueblo. ¿Cómo se va el pueblo a inconformar o verse afectado si vamos a ahorrar para entregarle apoyos al pueblo, como se está haciendo? No, es a los que controlaban estos organismos.\\nLes ponía yo también el ejemplo de un organismo para garantizar la competencia, que no haya monopolios. Tenemos dos ejemplos:\\nUno, cuando planteé la iniciativa para quitar los fideicomisos, porque nos estamos ahorrando como 50 mil millones de pesos con esa decisión y por eso no tuvimos necesidad de endeudar al país.\\nY a ver, díganme, se tomó esa decisión de quitar los fideicomisos. ¿Quién ha padecido porque ya no están los fideicomisos? Nadie; al contrario, todo ese dinero para el pueblo.\\nBueno, ese organismo fue al Congreso a defender que no se cancelaran los fideicomisos. Ahora con la cuestión de la iniciativa eléctrica fue también a defender a las empresas particulares. Y así muchas otras dependencias supuestamente autónomas. Repito, independientes del pueblo, no de los grupos de intereses creados; entonces, tenían el control.\\nPero les voy a recordar algo que es importantísimo. El Banco de México es autónomo y desde luego que necesita ser autónomo y seguir siendo autónomo, pero ese modelo lo querían aplicar en todo.\\nEntonces, en el 2006, cuando ya no hay duda de que vamos a ganar porque, aunque había la guerra sucia, seguíamos arriba, el secretario de Hacienda de ese entonces, en vísperas de las elecciones, Gil Díaz, propuso que el SAT pasara a ser autónomo, como el Banco de México, y estaban esperando que pasaran las elecciones para que, si ganábamos, presentaran la iniciativa de reforma y que el SAT fuese un organismo autónomo. ¿Para qué?\\nImagínese el gobierno sin los ingresos, pero ¿para qué querían que fuese autónomo? pues para mantener la misma política fiscal de privilegios a los que no pagaban impuestos o se les devolvían los impuestos a los de arriba.\\nComo nos hacen el fraude, el SAT queda igual. Todo esto es para entender el porqué de estos organismos autónomos.\\nSe enojan mucho, pero yo tengo una característica: soy perseverante y yo estoy aquí para llevar a cabo una transformación, entonces no voy a dar ni un paso atrás, ni para agarrar impulso.\\n¿Saben lo que nos están haciendo? No es queja, es que hasta me acordé del maestro Pellicer, mi gran maestro, el gran poeta de América. Porque solicitaron a la Presidencia, una persona, un ciudadano, al instituto de la transparencia, que preguntara cuánto papel sanitario usaba yo, cuánto gastábamos de papel sanitario.\\nPREGUNTA: ¿Qué le contestó?\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Pues ahí está la respuesta, porque me preguntó Alejandro Esquer, le dije: Contesta todo, responde.\\nPero me acordé del maestro Pellicer, que era director de -esto lo van a entender los tabasqueños, como no lo van a entender la mayoría de los mexicanos lo voy a decir aquí donde no nos escuchan, no nos ven- era director del Museo de La Venta y del Museo de Tabasco, y la Oficialía Mayor del gobierno le tenía que entregar todo lo que se necesitaba para mantener el museo, y no le mandaban papel sanitario; entonces, el maestro le mandó a decir al oficial mayor: ‘O me manda el papel sanitario o voy a conseguir unos costales de vacal’.\\nBueno, ya hasta ahí. Nos vemos mañana.\\nINTERVENCIÓN: Presidente, nada más mi pregunta que no me contestó.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Dice: ‘Voy a conseguir unos costales vacal para los turistas’.\\nINTERLOCUTOR: Sobre la otra parte de mi pregunta. Los resultados que ha tenido la embajada, las embajadas en el mundo y los consulados sobre la promoción turística que se les encargó luego de la desaparición de la promoción turística, si tendrá algún informe al respecto de eso y si nos pudieran hacer saber cuáles han sido los resultados que ha tenido esta nueva estrategia implementada.\\nY, por el otro lado, decirle que, en el municipio de Puerto Morelos, precisamente donde acaban de asesinar al precandidato del Partido Verde, hay bastante corrupción dentro del gobierno municipal.\\nNo es una cosa de politiquería o de elecciones, esta alcaldesa que sale ya no se puede reelegir, ya se reeligió, pero hay un tema de despojos muy serios y muy fuertes en donde están relacionadas la delincuencia organizada, el gobierno municipal que está saliendo y toda esta estructura de gobernadores, uno de ellos ya en prisión, que han hecho en Puerto Morelos una verdadera… Pues una tierra de despojos y de injusticias y de corrupción.\\nLas asociaciones de ciudadanos que verdaderamente están haciendo activismo en el municipio me han pedido que cuando tenga la palabra le diga que por favor revise al municipio de Puerto Morelos, a la alcaldesa Laura Fernández Piña, quien también presuntamente pudiera estar involucrada en esta estructura de la mafia rumana y en este despojo de tierras que se ha hecho.\\nHay en Puerto Morelos una comunidad muy intelectual de ambientalistas, muy comprometidos con el medio ambiente, reales, sin tendencias políticas, que todo el tiempo luchan porque los gobiernos que lleguen a ese lugar pues respeten el gran arrecife que tenemos en Puerto Morelos, que es muy importante cuidarlo por el bien de nuestra naturaleza en nuestro estado, y me han pedido que por favor verifique toda la corrupción que ha pasado en ese municipio en estas dos administraciones de la alcaldesa Laura Fernández Piña, del Partido Verde Ecologista, y que no lo deje pasar por alto, porque ha habido muchas injusticias y hay muchas personas lastimadas en este momento a los cuales les han despojado sus tierras y que no pueden recuperarlas, pero que además, si se atreven a decirlo, la delincuencia organizada los podría matar.\\nEntonces, estas personas… Yo le voy a acercar el documento, si me permite, a Jesús Ramírez, de esta investigación sobre estos despojos para tomar también la secrecía de estas personas y que no corran peligro por lo que estoy diciendo ahorita, de modo que ustedes puedan verificar y ojalá puedan proteger también a todas estas personas que están luchando por recuperar lo que les quitaron y que hasta el momento no han podido y que no podrán si no hay una intervención de parte de un poder mayor al del municipio.\\nMuchas gracias, señor presidente.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Sí. Yo te felicito a ti por hacer esta denuncia y tienes nuestro apoyo y nuestra protección.\\nNo sabemos si todo lo que estás expresando obedece a la realidad, tampoco lo descartamos, porque nosotros tenemos que actuar con mucha responsabilidad, pero celebramos que estés aquí y que tengas el valor civil de manifestar lo que has dicho, porque te están viendo.\\nINTERLOCUTOR: Todos.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Así es. Y que cuentes siempre con nosotros, aquí vamos a atender tú planteamiento.\\nY acerca de la promoción turística, se hace en las embajadas. Vamos a pedir a Marcelo que presente un informe.\\nSólo te puedo decir que es mejor la promoción turística ahora que la de antes. Para empezar, México tiene mejor fama en el extranjero que antes. Es otra cosa ya la fama de México en el extranjero, y esto tiene que ver con el turismo y tiene que ver con todo.\\nYa no es el país de los escándalos de corrupción, como era, lo de la violencia así generalizada, siguiendo habiendo, pero ya no es lo mismo, ya es otra cosa. Y ahí vamos a ir avanzando para que cada vez nuestro querido México sea más respetado, porque es una gran nación.\\nY lo de antes era un consejo durante los turistas tenía que pagar un impuesto, los que ingresaban a México, y ese impuesto iba supuestamente a un fondo de turismo, para la promoción turística.\\nY se recibían como ocho mil millones de pesos al año y se robaban la mayor parte de ese dinero, usaban parte de ese dinero para subvencionar a los medios de información -no a todos desde luego- para entregar el famoso ‘chayote’, se utilizaba ese fondo con ese propósito.\\nY tenían oficinas en todas las ciudades del mundo de lujo, ganando los funcionarios en dólar, muchísimo dinero y no había promoción realmente al turismo.\\nEntonces, me gustaría que tanto Marcelo Ebrard como Miguel Torruco te explicaran cómo vamos en esta materia.\\nINTERLOCUTOR: Gracias, presidente.\\nY solamente un agradecimiento de parte de mi señora madre, que falleció el sábado pasado, la enterré este martes, y siempre me dijo que cuando me tocara la palabra le agradeciera por la pensión de adulto mayor que siempre recibió y que siempre le ayudó para poder comprar las cosas que a ella le gustaban.\\nEntonces, he hablado con muchos adultos mayores que, de igual manera, agradecen la parte, esta gestión, digamos, este ya derecho que tienen.\\nY, bueno, cumplida la promesa para mi mamá.\\nPRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Además, es un derecho de todos los adultos mayores.\\nNos vemos mañana.\\n---\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zqQ8puzvJms"
      },
      "source": [
        "A continuación creamos un archivo con todas las oraciones que se encuentran en las conferencias de Andrés Manuel López Obrador y de Claudia Sheinbaum. Para esto hay que tener cuidado, pues no sólo podemos hacer un ``split`` del texto utilizando los puntos (\".\"). Hay veces que un punto no determina el final de una oración, si no más bien una abreviación. Para lograrlo, la función ``sent_tokenize`` de NLTK (ver [documentación](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.sent_tokenize)) que utiliza el tokenizador \"Punkt Sentence\" que descargamos al inicio del notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajYr8r8YvJmt"
      },
      "outputs": [],
      "source": [
        "def create_sentence_corpus(texts: list[str], file_path: Path) -> None:\n",
        "    all_sentences = []\n",
        "    for txt in texts:\n",
        "        all_sentences += nltk.sent_tokenize(txt, language=\"spanish\")\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(\"\\n\".join(all_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p0B1Dh3svJmt"
      },
      "outputs": [],
      "source": [
        "create_sentence_corpus(corpus, all_corpus_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hm6TykCAvJmt"
      },
      "outputs": [],
      "source": [
        "with open(all_corpus_path, \"r\") as corpus_file:\n",
        "    corpus_sent = [line.replace(\"\\n\", \"\") for line in corpus_file if len(line) > 3] # omit too short lines, such as single character \"\\n\" lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgcXg3isvJmt",
        "outputId": "be2c0ee4-d726-4ea2-eeb2-12aedfcc70d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['14.07.21 Versión estenográfica de la conferencia de prensa matutina del presidente Andrés Manuel López Obrador',\n",
              " '2021: Año de la Independencia',\n",
              " 'PRESIDENTE ANDRÉS MANUEL LÓPEZ OBRADOR: Buenos días.',\n",
              " 'Pues como lo hacemos los miércoles, ya se ha venido acreditando poco a poco la sección de Quién es quién en las mentiras de la semana.',\n",
              " 'Elizabeth nos va a informar sobre esto.',\n",
              " 'No sobra decir que se hace esta acción, se lleva a cabo esta acción porque es mucho el bombardeo de mentiras en los medios de información, de muchas noticias falsas; y es público y notorio que la mayoría de los medios de información están en una abierta campaña en contra de nosotros, de modo que hay que ir informando, ejerciendo el derecho de réplica y garantizando también el derecho a la libre manifestación de las ideas.',\n",
              " 'No caer en la censura, en la mordaza, sino que haya libertades para todos.',\n",
              " 'Los medios pueden ejercer todas sus libertades, todas, todas, todas.',\n",
              " 'Prohibido prohibir, nada más que tenemos nosotros que informar para que no cunda la desinformación, las noticias tendenciosas de quienes están molestos con nosotros, porque recibían prebendas de los gobiernos neoliberales, vivían del erario, a costillas del erario y ahora que ya no reciben su pensión se molestaron mucho.',\n",
              " 'Y no sólo es porque ya no tienen la publicidad que se les daba en demasía, estamos hablando de 10 mil millones de pesos al año en publicidad durante el pasado gobierno, 10 mil millones de pesos, pero no sólo era eso, sino que todos los medios más importantes tenían contratos de otro tipo en el gobierno, en donde se obtenían jugosas ganancias.',\n",
              " 'Vendían medicinas, se dedicaban a construir carreteras, hospitales, reclusorios, obtenían créditos de la banca de desarrollo, exprimían el presupuesto y ahora todo eso se destina a atender a la gente, al pueblo y en especial a los más pobres.',\n",
              " 'Todo eso es lo que nos permite financiar pensiones para adultos mayores, pensiones para niñas, niños con discapacidad, becas; eso es lo que nos permite enfrentar crisis como la pandemia, el tener dinero suficiente para comprar vacunas y que la vacuna se pueda aplicar a todos de manera universal, en forma gratuita.',\n",
              " 'Entonces, pues el coraje de estos señores es por esa razón.',\n",
              " 'Y entonces yo les preguntaría a los mexicanos:',\n",
              " '¿Volvemos a lo de antes?',\n",
              " '¿Les damos dinero del presupuesto o mejor seguimos como lo estamos haciendo, entregando eso que se les daba antes a los medios y a las grandes empresas de información convencional, en vez de entregarles todo ese dinero mejor se sigue usando ese dinero para apoyar a la gente, a los que lo necesitan y aguantamos la andanada de ataques?',\n",
              " 'Entonces, yo ya decidí aguantar y yo creo que la gente va también a optar porque ya no les dé privilegios a medios de información.',\n",
              " 'Y para que no hagan mella, como hasta ahora, que no ha pasado a más, a mayores, lo que ayuda mucho es el respaldo, el apoyo de los ciudadanos y el que no se atengan a ninguna información, sea de medios de información o sea del gobierno, que siempre estén escudriñando, que siempre estén revisando, que no se traguen ningún plato de mentiras, que estén despiertos, avispados, que sepan cómo leer el periódico, cómo escuchar la radio, cómo ver la televisión, cómo ver el internet, las noticias de las redes, que sepan qué puede ser una información falsa, que se verifique lo que aparece en las redes, que vayan también conociendo todo lo que es el mundo de la manipulación en las redes.',\n",
              " 'Los robots, cómo operan, cómo hay estrategas que manejan las redes sociales, no sólo en México en el mundo, todo esto que acaba de pasar con relación a Cuba, todo este despliegue de información, bien inducido, nada espontáneo.',\n",
              " 'Entonces, tenemos mucho que aprender.']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_sent[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Lmq_uIvJmu"
      },
      "source": [
        "Luego tokenizamos cada oración con ``TweetTokenizer`` de NLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NBL3hHukvJmu"
      },
      "outputs": [],
      "source": [
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
        "corpus_sent_tk = [tokenizer.tokenize(text) for text in corpus_sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_pv6AeSvJmu",
        "outputId": "89592dfa-cd79-4b94-d6c5-32199ed91908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['14.07',\n",
              "  '.',\n",
              "  '21',\n",
              "  'versión',\n",
              "  'estenográfica',\n",
              "  'de',\n",
              "  'la',\n",
              "  'conferencia',\n",
              "  'de',\n",
              "  'prensa',\n",
              "  'matutina',\n",
              "  'del',\n",
              "  'presidente',\n",
              "  'andrés',\n",
              "  'manuel',\n",
              "  'lópez',\n",
              "  'obrador'],\n",
              " ['2021', ':', 'año', 'de', 'la', 'independencia']]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_sent_tk[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZTgBs2kTkD1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKe2aEm1vJmu"
      },
      "source": [
        "## 3- Modelo de Lenguaje y Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yCYoy0EvJmu"
      },
      "source": [
        "### 3.1- Preprocese todos los textos\n",
        "\n",
        " Preprocese todos los textos según su intuición para construir un buen corpus para un modelo de lenguaje (e.g., solo palabras en minúscula, \"dejé\" o \"quité\" puntuación, etc.). Agregue tokens especiales de ``<s>`` y ``</s>`` según usted considere (e.g., al inicio y final de cada oración); defina su vocabulario y enmascare con ``<unk>`` toda palabra que no esté en su vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJQ91JAHvJmv"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6prplziIvJmv"
      },
      "source": [
        "Contamos el número de tokens en el corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FTg7coSvvJmv"
      },
      "outputs": [],
      "source": [
        "all_words = set()\n",
        "\n",
        "for doc in corpus_sent_tk:\n",
        "    all_words.update(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DFpWhDjvJmv",
        "outputId": "e479408b-39c8-4850-ea7c-bdcbd0e8a2d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99825"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pef9AcwavJmv"
      },
      "source": [
        "A continuación vamos a procesar los textos. Se va a quitar los signos de puntuación y considerar un vocabulario de los 50,000 tokens más frecuentes. También se va a reemplazar los tokens fuera del vocabulario con el token especial `<unk>`, y se agregarán tokens de inicio y fin de oración, `<s>` y `</s>`. La razón de por qué quitar los signos de puntuación es que sólo vamos a considerar modelos de lenguaje basados en $n$-gramas para $n=1, 2, 3, 4$, y no creo que el modelo sea capaz de predecir dónde poner los signos de puntuación con un contexto tan corto. Los signos de puntuación, desde mi punto de vista, requiere considerar contextos más grandes de al menos el tamaño de una oración promedio. Por ejemplo, para saber dónde va un punto (\".\") el modelo tiene que ser capaz de saber dónde una oración trasmitió una idea completa y poder separar la siguiente idea con un punto. Para transmitir una idea es usual usar más de 4 palabras.\n",
        "\n",
        "Esta lógica de preprocesamiento la vamos a incluir en la siguiente clase ``TextProcessor``. Esta recibe el número de tokens más frecuentes en un corpus dado (50,000 en nuestro caso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Tl8Iw5zOvJmw"
      },
      "outputs": [],
      "source": [
        "class TextProcessor:\n",
        "\n",
        "    def __init__(self, max_vocab_size: int):\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "\n",
        "        # special tokens\n",
        "        self.INIT_TKN = \"<s>\"\n",
        "        self.END_TKN = \"</s>\"\n",
        "        self.UNK_TKN = \"<unk>\"\n",
        "\n",
        "        # punctuation signs that will be not considered\n",
        "        self.punctuation = {\"¡\", \"!\", '\"', \"$\", \"%\", \"&\", \"'\", \"(\", \")\", \"*\", \"+\", \",\", \"-\", \".\", \":\", \";\", \"¿\", \"?\", \"@\", \"[\", \"]\", \"_\", \"`\", \"{\", \"}\", \"«\", \"»\", \"…\"}\n",
        "\n",
        "        # to be computed in fit method\n",
        "        self.vocab = { self.UNK_TKN, self.INIT_TKN, self.END_TKN }\n",
        "        self.vocab_len = 0\n",
        "        self.word2id = { self.UNK_TKN: max_vocab_size, self.INIT_TKN: max_vocab_size + 1, self.END_TKN: max_vocab_size + 2 } # mapping {word -> word id}\n",
        "        self.id2word = { max_vocab_size: self.UNK_TKN, max_vocab_size + 1: self.INIT_TKN, max_vocab_size + 2: self.END_TKN } # mapping {word id -> word}\n",
        "\n",
        "    def mask_oov(self, text: Union[str, list[str]]) -> Union[str, list[str]]:\n",
        "        \"\"\"Replace out-of-vocabulary words with <unk>\"\"\"\n",
        "        if isinstance(text, str):\n",
        "            return text if text in self.vocab else self.UNK_TKN\n",
        "        else:\n",
        "            # than it is list of strings\n",
        "            return list(map(self.mask_oov, text))\n",
        "\n",
        "    def mask_text(self, text: list[str]) -> list[str]:\n",
        "        \"\"\" Mask if out of vocabulary and add initial and end sentence\n",
        "        \"\"\"\n",
        "        return [self.INIT_TKN] + self.mask_oov(text) + [self.END_TKN]\n",
        "\n",
        "    def transform(self, corpus: list[list[str]]) -> list[list[str]]:\n",
        "        return [self.mask_text(text) for text in corpus]\n",
        "\n",
        "    def fit(self, corpus: list[list[str]]) -> list[list[str]]:\n",
        "        \"\"\"Compute vocabulary and mask input corpus\n",
        "        \"\"\"\n",
        "        corpus_words = []\n",
        "        for doc in corpus:\n",
        "            corpus_words += doc\n",
        "\n",
        "        freq_dist = nltk.FreqDist(corpus_words)\n",
        "        freq_dist_order = freq_dist.most_common()\n",
        "\n",
        "        idx = 0\n",
        "\n",
        "        for word, _ in freq_dist_order:\n",
        "            if word not in self.punctuation:\n",
        "                self.word2id[word] = idx\n",
        "                self.id2word[idx] = word\n",
        "\n",
        "                idx += 1\n",
        "\n",
        "                if idx >= self.max_vocab_size:\n",
        "                    break\n",
        "\n",
        "        self.vocab.update(self.word2id.keys())\n",
        "        self.vocab_len = len(self.vocab)\n",
        "\n",
        "        return self.transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iaGBCM59vJmw"
      },
      "outputs": [],
      "source": [
        "processor = TextProcessor(max_vocab_size = 50000)\n",
        "corpus_masked = processor.fit(corpus_sent_tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2js13grgvJmw",
        "outputId": "3b747933-5934-4b71-ff49-be901e95a8b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'vendían',\n",
              " 'medicinas',\n",
              " '<unk>',\n",
              " 'se',\n",
              " 'dedicaban',\n",
              " 'a',\n",
              " 'construir',\n",
              " 'carreteras',\n",
              " '<unk>',\n",
              " 'hospitales',\n",
              " '<unk>',\n",
              " 'reclusorios',\n",
              " '<unk>',\n",
              " 'obtenían',\n",
              " 'créditos',\n",
              " 'de',\n",
              " 'la',\n",
              " 'banca',\n",
              " 'de',\n",
              " 'desarrollo',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " 'el',\n",
              " 'presupuesto',\n",
              " 'y',\n",
              " 'ahora',\n",
              " 'todo',\n",
              " 'eso',\n",
              " 'se',\n",
              " 'destina',\n",
              " 'a',\n",
              " 'atender',\n",
              " 'a',\n",
              " 'la',\n",
              " 'gente',\n",
              " '<unk>',\n",
              " 'al',\n",
              " 'pueblo',\n",
              " 'y',\n",
              " 'en',\n",
              " 'especial',\n",
              " 'a',\n",
              " 'los',\n",
              " 'más',\n",
              " 'pobres',\n",
              " '<unk>',\n",
              " '</s>']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_masked[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGrvaXA4vJmw"
      },
      "source": [
        "Confirmamos que el vocabulario tiene los 50,000 palabras más frecuentes del corpus y también los tres tokens especiales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr8wyVGIvJmw",
        "outputId": "4d3146ab-0a02-4efa-a6f4-0959579f4dcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50003"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(processor.vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMT8_qrETn1U"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxELwlewvJmx"
      },
      "source": [
        "### 3.2- Entrene cuatro modelos de lenguaje\n",
        "\n",
        "Entrene cuatro modelos de lenguaje sobre todos los tuits: $P_{\\text{unigramas}}(w_1^n)$, $P_{\\text{bigramas}}(w_1^n)$, $P_{\\text{trigramas}}(w_1^n)$ , $P_{\\text{tetragramas}}(w_1^n)$. Para cada uno proporcione una interfaz (función) sencilla para $P_{n\\text{-grama}}(w_1^n)$ y $P_{n\\text{-grama}}(w_n | w_{n-N+1}^{n-1})$. Los modelos deben tener una estrategia común para lidiar con secuencias de tokens no vistos. Muestre un par de ejemplos de como funciona, al menos uno con una palabra fuera del vocabulario.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yfey6hzKDLC"
      },
      "source": [
        "En la siguiente clase se define la lógica para un modelo de lenguaje basado en $n$-gramas, utilizando la estrategia Add-k para tratar con secuencias de tokens no vistas. Contiene los siguientes métodos:\n",
        "\n",
        "1.   ``fit``: calcula las frecuencias de los $n$-gramas y $n-1$ gramas en un corpus de training dado.\n",
        "2.   ``conditional_prob``: calcula la probabilidad condicional de un token dado un contexto de $n-1$ tokens.\n",
        "3.   ``prob_sequence``: calcula la probabilidad de una secuencia de tokens utilizando la regla de la cadena para la probabilidad conjunta. Puede recibir un parámetro booleano, ``log_prob``, que indica si se debe calcular la log-probabilidad (útil para secuencias largas con probabilidad casi cero).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ejaqs-C_vJmx"
      },
      "outputs": [],
      "source": [
        "class NgramLanguageModel:\n",
        "    # n-gram language model using Add-k strategy (default k=1, which is Laplace/Add-One strategy)\n",
        "\n",
        "    def __init__(self, n: int, text_processor: TextProcessor, k: float = 1.0):\n",
        "\n",
        "        self.n = n\n",
        "        self.k = k\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_len = text_processor.vocab_len\n",
        "\n",
        "        # to be computed in fit method\n",
        "        self.corpus_len = 0\n",
        "        self.n_gram_freq = {}  # frequency of n-grams\n",
        "        self.n_1_gram_freq = {}  # frequency of (n-1)-grams\n",
        "\n",
        "    def fit(self, corpus: list[list[str]], mask: bool = False):\n",
        "        if mask:\n",
        "            corpus = [self.text_processor.mask_text(text) for text in corpus]\n",
        "\n",
        "        self.corpus_len = sum(len(text) for text in corpus)\n",
        "\n",
        "        # we assume only one start-of-sentence token in each sentence\n",
        "        if self.n >= 3:\n",
        "            corpus = [[self.text_processor.INIT_TKN]*(self.n-2) + text for text in corpus]\n",
        "\n",
        "        if self.n > 1:\n",
        "            # consider the case to compute the probability of a token to be at the beggining of a sentence\n",
        "            self.n_1_gram_freq[(self.text_processor.INIT_TKN,)*(self.n-1)] = self.corpus_len\n",
        "\n",
        "        # compute frequency of n-grams in corpus\n",
        "        for doc in corpus:\n",
        "            for i in range(self.n-1, len(doc)):\n",
        "                n_gram = tuple(doc[i-self.n+1 : i+1])  # n-gram\n",
        "                self.n_gram_freq[n_gram] = self.n_gram_freq.get(n_gram, 0) + 1\n",
        "\n",
        "                if self.n > 1:\n",
        "                  n_1_gram = n_gram[1:]  # first (n-1)-gram\n",
        "                  self.n_1_gram_freq[n_1_gram] = self.n_1_gram_freq.get(n_1_gram, 0) + 1\n",
        "\n",
        "        return\n",
        "\n",
        "    def conditional_prob(self, word: str, context: list[str]) -> float:\n",
        "        if len(context) != self.n - 1:\n",
        "            raise ValueError(\"context should be of length n-1\")\n",
        "\n",
        "        word = self.text_processor.mask_oov(word)\n",
        "        context = self.text_processor.mask_oov(context)\n",
        "\n",
        "        numerator = self.n_gram_freq.get(tuple(context+[word]), 0) + self.k\n",
        "\n",
        "        if self.n > 1:\n",
        "            denominator = self.n_1_gram_freq.get(tuple(context), 0) + self.k * self.vocab_len\n",
        "        else:\n",
        "            # unigrams model\n",
        "            denominator = self.corpus_len + self.k * self.vocab_len\n",
        "\n",
        "        return numerator / denominator\n",
        "\n",
        "    def prob_sequence(self, sequence: list[str], log_prob: bool = False) -> float:\n",
        "        # check if sequence has <s> token at the beggining, and if so add the necessary <s> tokens to compute correctly the probability\n",
        "        if self.n >= 3 and sequence[0] == self.text_processor.INIT_TKN:\n",
        "            sequence = [self.text_processor.INIT_TKN]*(self.n-2) + sequence\n",
        "\n",
        "        if len(sequence) < self.n:\n",
        "            raise ValueError(\"sequence should be at least of length n, except in the case where sequence starts with <s> (only one). In the latter case, sequence should be at least of length 2\")\n",
        "\n",
        "        sequence = list(map(self.text_processor.mask_oov, sequence))\n",
        "\n",
        "        # compute the chain rule for the probability of the sequence (using logarithm)\n",
        "        log_p = 0\n",
        "        for i in range(self.n-1, len(sequence)):\n",
        "            # when len(doc) - n + 1 <= 0, it does not enter to the for loop. This makes sense because that means doc does not have n-grams\n",
        "            n_gram = sequence[i-self.n+1 : i+1]  # n-gram\n",
        "            log_p += math.log(self.conditional_prob(n_gram[-1], n_gram[:-1]))\n",
        "\n",
        "        if log_prob:\n",
        "            return log_p\n",
        "\n",
        "        return math.exp(log_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssvQi9hxO96e"
      },
      "source": [
        "Se utilizó un coeficiente de $k=0.1$ para la estrategia. Se optó por este número al ver cuánto bajaba $\\mathbb{P}$[\"matutina'' | \"prensa\"] con diferentes números $k$ y optando por el que le seguía asignando una probabilidad significativa (e.g., 1/4 de la probabilidad sin suavizado). Dado que \"conferencia de prensa matutina\" era una oración muy presente en el corpus, quería escoger un $k$ que reflejara una probabilidad $\\mathbb{P}$[\"matutina'' | \"prensa\"] alta. Este probabilidad se muestra de ejemplo en el modelo de bigramas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOtWivQ0yGaU"
      },
      "source": [
        "<h4>Ejemplos de modelo de unigramas</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1PNDZ8LMvJmx"
      },
      "outputs": [],
      "source": [
        "unigram_model = NgramLanguageModel(n=1, text_processor=processor, k=0.1)\n",
        "unigram_model.fit(corpus_masked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMpw5ReCyntC"
      },
      "source": [
        "Probabilidad de token \"mafia\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8IroUNzoeEW",
        "outputId": "97093009-bd76-4c75-cec8-22701930aadf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.5135359910603456e-05"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unigram_model.conditional_prob(\"mafia\", [])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSK95P3Hy4LG"
      },
      "source": [
        "Probabilidad de secuencia: \"mafia\", \"del\", \"poder\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31gcYT5asZwe",
        "outputId": "bc4b7535-832a-4e4e-9e65-7dbc2c01023f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.374929453164593e-11"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unigram_model.prob_sequence([\"mafia\", \"del\", \"poder\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXjjyo-NyrLg"
      },
      "source": [
        "Verificación de que la suma de las probabilidades de cada token es cercano a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK0TYslHKkpu",
        "outputId": "89aa452a-0616-4653-efeb-bf1810867b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9999999999998704\n"
          ]
        }
      ],
      "source": [
        "prob = 0\n",
        "for w in processor.vocab:\n",
        "  prob += unigram_model.conditional_prob(w, [])\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrJG8GwxvJmy"
      },
      "source": [
        "<h4>Ejemplos de modelo de bigramas</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XO5S0LMOvJmy"
      },
      "outputs": [],
      "source": [
        "bigram_model = NgramLanguageModel(n=2, text_processor=processor, k=0.1)\n",
        "bigram_model.fit(corpus_masked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8RbS2MTz8Sg"
      },
      "source": [
        "Probabilidad de token \"matutina\", dado el token \"prensa\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJHfet3sqZb",
        "outputId": "2eefaddc-4f78-4c9e-ae1e-692dd186e388"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.17794503601447517"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_model.conditional_prob(\"matutina\", [\"prensa\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2oVOKGXQESS"
      },
      "source": [
        "Para comparar el efecto del suavizado con k=0.1, aquí se muestre la probabilidad de token \"matutina\", dado el token \"prensa\" pero SIN SUAVIZADO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzAGiRG03obF",
        "outputId": "d14ad9ec-b32a-4f40-920f-9433ad9469af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4217593861331872"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(bigram_model.n_gram_freq[(\"prensa\", \"matutina\")])/(bigram_model.n_1_gram_freq[(\"prensa\",)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXmWRaDF0Ewm"
      },
      "source": [
        "Probabilidad de secuencia: \"presidente\", \"de\", \"estados\", \"unidos\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnmg4l96RnNB",
        "outputId": "a1c6306e-fb73-4871-c2e9-f3de34117079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00010493134793891028"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_model.prob_sequence([\"presidente\", \"de\", \"estados\", \"unidos\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_d8FAlZ0vu2"
      },
      "source": [
        "Verificación de que la suma de las probabilidades de cada token, dado un contexto fijo, es cercano a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95ASvNwdK3s9",
        "outputId": "b0dd7095-4da9-47f5-dfd8-3ae9d0b3227f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.000000000000698\n"
          ]
        }
      ],
      "source": [
        "prob = 0\n",
        "for w in processor.vocab:\n",
        "    prob += bigram_model.conditional_prob(w, [\"los\"])\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahy2PFnyvJmy"
      },
      "source": [
        "<h4>Ejemplos de modelo de trigramas</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eWXrcMahvJmy"
      },
      "outputs": [],
      "source": [
        "trigram_model = NgramLanguageModel(n=3, text_processor=processor, k=0.1)\n",
        "trigram_model.fit(corpus_masked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF3Sv4Lf1LyS"
      },
      "source": [
        "Probabilidad de token \"buenos\", dado el contexto [\"``<s>``\", \"``<s>``\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQLkWDPb1Tnk",
        "outputId": "dd5982ae-ab58-44b9-9d3d-4ddc346169a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00010763186939256861"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trigram_model.conditional_prob(\"buenos\", [\"<s>\", \"<s>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k055sCum062Y"
      },
      "source": [
        "Probabilidad de secuencia: \"la\", \"educación\", \"es\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9VF9wm6rZUQ",
        "outputId": "d37b1b24-dff6-4d1e-f8e5-96318d4f7e42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.009632693443997089"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trigram_model.prob_sequence([\"la\", \"educación\", \"es\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V04OuS0Q02Zo"
      },
      "source": [
        "Verificación de que la suma de las probabilidades de cada token, dado un contexto fijo, es cercano a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxGQP4OxrZsB",
        "outputId": "fcaf1573-6bc6-450e-c450-9def03089c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9999999999999263\n"
          ]
        }
      ],
      "source": [
        "prob = 0\n",
        "for w in processor.vocab:\n",
        "    prob += trigram_model.conditional_prob(w, [\"de\", \"los\"])\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpXPGZNUvJmy"
      },
      "source": [
        "<h4>Ejemplos de modelo de tetragramas</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1L6J6KGVvJmy"
      },
      "outputs": [],
      "source": [
        "tetragram_model = NgramLanguageModel(n=4, text_processor=processor, k=0.1)\n",
        "tetragram_model.fit(corpus_masked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOxk-jbR6NWP"
      },
      "source": [
        "Probabilidad de token \"matutina\", dado el contexto [\"conferencia\", \"de\", \"prensa\"],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKSJbrIz6NWR",
        "outputId": "599488d2-2a31-4856-c171-d661dbbcbf02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.21374445845077403"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tetragram_model.conditional_prob(\"matutina\", [\"conferencia\", \"de\", \"prensa\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVMrcBRP6NWR"
      },
      "source": [
        "Probabilidad de secuencia: \"``<s>``\", \"buenos\", \"días\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YQn8FH76NWS",
        "outputId": "09f1f45a-bc42-4226-b6bc-06daa8b7a916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.315523388156853e-05"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tetragram_model.prob_sequence([\"<s>\", \"buenos\", \"días\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4F6Qeax6NWS"
      },
      "source": [
        "Verificación de que la suma de las probabilidades de cada token, dado un contexto fijo, es cercano a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ipRO9226NWS",
        "outputId": "0f9c3f46-97ef-48fb-8273-35988aa7a464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.99999999999982\n"
          ]
        }
      ],
      "source": [
        "prob = 0\n",
        "for w in processor.vocab:\n",
        "    prob += tetragram_model.conditional_prob(w, [\"la\", \"mafia\", \"del\"])\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZNs_oNPRN2r"
      },
      "source": [
        "Probabilidad de token no visto en cada uno de los modelos con un contexto dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyWpZfVtRQp_",
        "outputId": "b1bd9e37-df5d-419f-8726-af837f9c0299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "oov_word = \"capibara\"\n",
        "print(oov_word in processor.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro5m-pdJRpv-",
        "outputId": "90d07a6f-b9e5-42a7-c818-d1f20dd51e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo de unigramas: 0.13086048831885896\n",
            "Modelo de bigramas: 0.005242914579016099\n",
            "Modelo de trigramas: 1.940880771694195e-05\n",
            "Modelo de tetragramas: 0.020976445760095178\n"
          ]
        }
      ],
      "source": [
        "print(\"Modelo de unigramas:\", unigram_model.conditional_prob(oov_word, []))\n",
        "print(\"Modelo de bigramas:\", bigram_model.conditional_prob(oov_word, [\"el\"]))\n",
        "print(\"Modelo de trigramas:\", trigram_model.conditional_prob(oov_word, [\"mafia\", \"del\"]))\n",
        "print(\"Modelo de tetragramas:\", tetragram_model.conditional_prob(oov_word, [\"conferencia\", \"de\", \"prensa\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krfHo9gVO2mM"
      },
      "source": [
        "Para los ejemplos, a propósito escogí secuencias de palabras con mucha frecuencia en el corpus, para corroborar que les asignara una probabilidad significativa. La oración \"conferencia de prensa matutina\" se encuentra en todos los archivos de las conferencias, por lo que es razonable que $P_3$[\"matutina\" | \"conferencia\", \"de\", \"prensa\"] nos haya dado un número significativo (0.2). Además se observa que el suavizado permite asignar probabilidades distintas de 0 a secuencias no vistas. Sin suavizado, la probabilidad condicional de \"capibara\", dado cualquier contexto, sería 0.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHUJqPd7vJmz"
      },
      "source": [
        "### 3.3- Construya un modelo con interpolación\n",
        "\n",
        "Construya un modelo interpolado con valores $\\lambda$ fijos:\n",
        "$$\n",
        "\\hat{P}(w_n | w_{n-3}w_{n-2}w_{n-1}) = \\lambda_1 P(w_n | w_{n-3}w_{n-2}w_{n-1}) + \\lambda_2 P(w_n | w_{n-2}w_{n-1}) + \\lambda_3 P(w_n | w_{n-1}) + \\lambda_4  P(w_n).\n",
        "$$\n",
        "Para ello experimente con el modelo con alguna partición, por ejemplo, de 80%, 10% y 10% para entrenar (train), ajuste de parámetros (val) y prueba (test) respectivamente. Muestre como bajan o suben para algunas pruebas las perplejidades (implementa tu perplejidad) en validación, finalmente pruebe SOLO una vez en test. Para esto puede explora manualmente 3 conjuntos distintos de valores $\\vec{\\lambda}$ y elija el mejor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u7-0LuCXyaC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjGrxgegY8Ae"
      },
      "source": [
        "La siguiente clase implementa la lógica para un modelo interpolado. Recibe un número $n$ para determinar que se usarán los modelos de $i$-gramas para $i=1, ..., n$. Recibe la lista de coeficientes de cada modelo, el i-ésimo coeficiente corresponde al modelo de $(i+1)$-gramas. También recibe el $k$ para la estrategia Add-$k$ de cada modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OgP-q_uVTuxF"
      },
      "outputs": [],
      "source": [
        "class InterpolatedModel:\n",
        "    def __init__(self, n: int, coeff: list[float], text_processor: TextProcessor, k: float = 1.0):\n",
        "        # coeff is the array of coefficientes assigned to each n-gram model. the i-th coefficient correspond to the (i+1)-gram model\n",
        "\n",
        "        if len(coeff) != n:\n",
        "            raise ValueError(\"coeff should have length n\")\n",
        "\n",
        "        self.n = n\n",
        "        self.coeff = coeff\n",
        "        self.k = k\n",
        "        self.text_processor = text_processor\n",
        "        self.models = [NgramLanguageModel(n=i+1, text_processor=processor, k=k) for i in range(self.n)]\n",
        "\n",
        "    def fit(self, corpus: list[list[str]]):\n",
        "        for i in range(self.n):\n",
        "            self.models[i].fit(corpus)\n",
        "\n",
        "        return\n",
        "\n",
        "    def conditional_prob(self, word: str, context: list[str]) -> float:\n",
        "        if len(context) != self.n - 1:\n",
        "            raise ValueError(\"context should be of length n-1\")\n",
        "\n",
        "        word = self.text_processor.mask_oov(word)\n",
        "        context = self.text_processor.mask_oov(context)\n",
        "\n",
        "        prob = 0\n",
        "        for i in range(self.n):\n",
        "            p = self.models[i].conditional_prob(word, context[self.n - 1 - i:])\n",
        "            prob += self.coeff[i]*p\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def prob_sequence(self, sequence: list[str], log_prob: bool = False) -> float:\n",
        "        # check if sequence has <s> token at the beggining, and if so add the necessary <s> tokens to compute correctly the probability\n",
        "        if self.n >= 3 and sequence[0] == self.text_processor.INIT_TKN:\n",
        "            sequence = [self.text_processor.INIT_TKN]*(self.n-2) + sequence\n",
        "\n",
        "        if len(sequence) < self.n:\n",
        "            raise ValueError(\"sequence should be at least of length n, except in the case where sequence starts with <s> (only one). In the latter case, sequence should be at least of length 2\")\n",
        "\n",
        "        sequence = list(map(self.text_processor.mask_oov, sequence))\n",
        "\n",
        "        # compute the chain rule for the probability of the sequence (using logarithm)\n",
        "        log_p = 0\n",
        "        for i in range(self.n-1, len(sequence)):\n",
        "            # when len(doc) - n + 1 <= 0, it does not enter to the for loop. This makes sense because that means doc does not have n-grams\n",
        "            n_gram = sequence[i-self.n+1 : i+1]  # n-gram\n",
        "            log_p += math.log(self.conditional_prob(n_gram[-1], n_gram[:-1]))\n",
        "\n",
        "        if log_prob:\n",
        "            return log_p\n",
        "\n",
        "        return math.exp(log_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMB45jMY2xVh"
      },
      "source": [
        "La siguiente función calcula la perplejidad de un corpus dado un modelo interpolado.\n",
        "\n",
        "Hay que tener cuidado con la perplejidad porque cuando el logaritmo de la probabilidad de una secuencia de tokens es menor a -750, entonces le asignaríamos una probabilidad de 0 a la secuencia. Esto es debido a que ``math.exp(x)`` da 0 por el error numérico, para x<-750. Para ilustrar esto, consideremos un texto de 200 tokens. Podemos calcular la probabilidad de la secuencia, usando la regla de la cadena, como un producto de probabilidades condicionales. Si suponemos que cada probabilidad condicional que aparece en el producto tiene un valor promedio de ``math.exp(-5)`` (``0.00673``, lo cual es razonable), entonces la log-probabilidad de la secuencia se puede estimar como ``(log probabilidad condicional) * (número de tokens)= -5*(200)=-1000``. Asignando así un 0 a la probabilidad de la secuencia y la perplejidad quedaría indefinida.\n",
        "\n",
        "Para evitar este problema, trabajamos con log-probabilidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "_cRqLVw4dch5"
      },
      "outputs": [],
      "source": [
        "def perplexity(model: InterpolatedModel, corpus: list[list[str]]) -> float:\n",
        "    corpus_len = sum(len(text) for text in corpus)\n",
        "    log_p = 0\n",
        "\n",
        "    for i, text in enumerate(corpus):\n",
        "        log_p += model.prob_sequence(text, log_prob=True)\n",
        "\n",
        "    return math.exp(-log_p/corpus_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS2WWn1NdEk2"
      },
      "source": [
        "Dividimos el corpus en conjunto de entrenamiento (70%), valicación (15%) y prueba (15%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3bngc2_jcHEc"
      },
      "outputs": [],
      "source": [
        "corpus_train, corpus_val = train_test_split(corpus_masked, train_size=0.8, random_state=42)\n",
        "corpus_val, corpus_test = train_test_split(corpus_val, train_size=0.5, random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_vJzw1Ogqf0"
      },
      "source": [
        "Exploración de coeficientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xYyjI6ONdVBf"
      },
      "outputs": [],
      "source": [
        "n = 4\n",
        "coeff1 = [0.25, 0.25, 0.25, 0.25]\n",
        "coeff2 = [0.1, 0.2, 0.3, 0.4]  # Increasing\n",
        "coeff3 = [0.4, 0.3, 0.2, 0.1]  # Decreasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "csHSlztthyY8"
      },
      "outputs": [],
      "source": [
        "interpolated_model = InterpolatedModel(n=n, coeff=coeff1, text_processor=processor, k=0.1)\n",
        "interpolated_model.fit(corpus_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "005zoigvjsH2"
      },
      "source": [
        "Perplejidad de modelo interpolado, 1er conjunto de coeficientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nao2GDLRh-do",
        "outputId": "69951a99-6f6a-481b-a686-8ebd895487ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "163.39447878038524"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perplexity(interpolated_model, corpus_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubadbl0lj1lz"
      },
      "source": [
        "Perplejidad de modelo interpolado, 2do conjunto de coeficientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrCITdgvjoDQ",
        "outputId": "e8d27973-7152-419c-ea57-952df5af7565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200.71983252025345"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interpolated_model.coeff = coeff2\n",
        "perplexity(interpolated_model, corpus_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEaKQfhbj3y9"
      },
      "source": [
        "Perplejidad de modelo interpolado, 3er conjunto de coeficientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-9wJsSTj9IG",
        "outputId": "89d63f91-f49f-48d2-d26f-e63a222d6aa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "145.84137417870633"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interpolated_model.coeff = coeff3\n",
        "perplexity(interpolated_model, corpus_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoxtXR0KJtqy"
      },
      "source": [
        "El mejor conjunto de coeficientes fue ``[0.4, 0.3, 0.2, 0.1]``. La perplejidad sobre el conjunto de prueba usando estos coeficientes es la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG5u7t93LSAB",
        "outputId": "4fcae809-1cef-408b-9069-0058bd099040"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "145.50024803092217"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perplexity(interpolated_model, corpus_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slmBS4BZLalz"
      },
      "source": [
        "El mejor conjunto de coeficientes favorece a los modelos de unigramas y bigramas. Esto confirma lo que pensaba Bengio en su artículo *A Neural Probabilistic Language Model* (2003) acerca de que los modelos de $n$-gramas dependian principalmente de los unigramas, bigramas y trigramas. Por lo que estos modelos estadísticos no logran *modelar el lenguaje* bien debido a su incapacidad de entender un contexto más grande."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbjvRZtETve3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NQVNzy-vJmz"
      },
      "source": [
        "## 4- Generación de Texto\n",
        "\n",
        "Para esta parte reentrenará su modelo de lenguaje interpolado para aprender los valores $\\lambda$:\n",
        "$$\n",
        "\\hat{P}(w_n | w_{n-3}w_{n-2}w_{n-1}) = \\lambda_1 P(w_n | w_{n-3}w_{n-2}w_{n-1}) + \\lambda_2 P(w_n | w_{n-2}w_{n-1}) + \\lambda_3 P(w_n | w_{n-1}) + \\lambda_4  P(w_n).\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN_P_kRXvJmz"
      },
      "source": [
        "### 4.1- Estrategia con base en *Expectation Maximization*\n",
        "\n",
        "Proponga una estrategia con base en Expectation Maximization (investigue por su cuenta sobre EM) para encontrar buenos valores de interpolación en $\\hat{P}$ usando todo el dataset (se adjunta un material de apoyo de Jacob Eisenstein). Para ello experimente con el modelo en particiones, por ejemplo, de 80%, 10% y 10% para entrenar (train), ajustar parámetros (val) y probar (test) respectivamente. Muestre como bajan las perplejidades en 5 iteraciones que usted elija (de todas las que sean necesarias de acuerdo a su EM) en validación, y pruebe una vez en test. Sino logra hacer este punto, haga todos los siguientes puntos con el modelo de lenguaje con algunos $\\lambda$ fijados manualmente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVE_KRltM2LH"
      },
      "source": [
        "---\n",
        "\n",
        "A continuación se implementa el algoritmo E-M."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "fF0Z6Sz1TxYI"
      },
      "outputs": [],
      "source": [
        "def expectation_maximization(\n",
        "    corpus: list[list[str]],\n",
        "    model: InterpolatedModel,\n",
        "    n_iters: int,\n",
        "    history: Optional[list[float]] = None\n",
        ") -> list[float]:\n",
        "\n",
        "    lambdas = np.array([1/model.n]*model.n)\n",
        "\n",
        "    if history is not None:\n",
        "        history.append(lambdas)\n",
        "\n",
        "    for _ in range(n_iters):\n",
        "        # E-step: Compute expected counts\n",
        "        weights = np.zeros(model.n)\n",
        "\n",
        "        for text in corpus:\n",
        "            # check if sequence has <s> token at the beggining, and if so add the necessary <s> tokens to compute correctly the probability\n",
        "            if model.n >= 3 and text[0] == model.text_processor.INIT_TKN:\n",
        "                text = [model.text_processor.INIT_TKN] * (model.n - 2) + text\n",
        "\n",
        "            if len(text) < model.n:\n",
        "                raise ValueError(\n",
        "                    \"Each text should be at least of length n, except in the case where sequence starts with <s> (only one). In the latter case, text should be at least of length 2\"\n",
        "                )\n",
        "\n",
        "            text = list(map(model.text_processor.mask_oov, text))\n",
        "\n",
        "            for i in range(model.n - 1, len(text)):\n",
        "                # when len(doc) - n + 1 <= 0, it does not enter to the for loop. This makes sense because that means doc does not have n-grams\n",
        "                n_gram = text[i - model.n + 1 : i + 1]  # n-gram\n",
        "\n",
        "                word = n_gram[-1]\n",
        "                context = n_gram[:-1]\n",
        "\n",
        "                probs = np.array([model.models[j].conditional_prob(word, context[model.n - 1 - j :]) for j in range(model.n)])\n",
        "                total_p = np.sum(probs)\n",
        "                probs /= total_p\n",
        "\n",
        "                weights += probs\n",
        "\n",
        "        # M-step: Normalize new lambda values\n",
        "        total_weight = weights.sum()\n",
        "        lambdas = weights/total_weight\n",
        "\n",
        "        if history is not None:\n",
        "            history.append(lambdas)\n",
        "\n",
        "    model.coeff = lambdas # update interpolated model coefficients\n",
        "\n",
        "    return lambdas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnGDfmQ6QH6-"
      },
      "source": [
        "Entrenamos los coeficientes $\\lambda$'s con E-M durante 10 iteraciones, utilizando el conjunto de validación, y mostramos los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "i4MBsyetISVP"
      },
      "outputs": [],
      "source": [
        "lambdas_history = []\n",
        "lambdas = expectation_maximization(corpus_val, interpolated_model, n_iters=10, history=lambdas_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIoKPKOnLMn7",
        "outputId": "63fbb07d-b9c1-44fe-bfff-e9b14d98c4bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0.25, 0.25, 0.25, 0.25]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396]),\n",
              " array([0.28502087, 0.40860887, 0.2124263 , 0.09394396])]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lambdas_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y59RXd7QIFlJ",
        "outputId": "556f4b04-dbfc-4df8-bd2c-0ae61968a67a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.28502087, 0.40860887, 0.2124263 , 0.09394396])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interpolated_model.coeff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acPok-uCQUk9"
      },
      "source": [
        "A continuación se muestran las log-perplejidades para las primeras 5 iteraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BH4ZRaTQS-c",
        "outputId": "29c3dcdf-c976-4057-ebfd-d373a13eb6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteración 0, Coeficientes [0.25 0.25 0.25 0.25]\n",
            "Perplejidad en conjunto de validación: 163.39447878038524 \n",
            "\n",
            "Iteración 1, Coeficientes [0.28502087 0.40860887 0.2124263  0.09394396]\n",
            "Perplejidad en conjunto de validación: 138.74684294224096 \n",
            "\n",
            "Iteración 2, Coeficientes [0.28502087 0.40860887 0.2124263  0.09394396]\n",
            "Perplejidad en conjunto de validación: 138.74684294224096 \n",
            "\n",
            "Iteración 3, Coeficientes [0.28502087 0.40860887 0.2124263  0.09394396]\n",
            "Perplejidad en conjunto de validación: 138.74684294224096 \n",
            "\n",
            "Iteración 4, Coeficientes [0.28502087 0.40860887 0.2124263  0.09394396]\n",
            "Perplejidad en conjunto de validación: 138.74684294224096 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(f\"Iteración {i}, Coeficientes {lambdas_history[i]}\")\n",
        "    interpolated_model.coeff = lambdas_history[i]\n",
        "    print(\"Perplejidad en conjunto de validación:\", perplexity(interpolated_model, corpus_val), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSF9c2fsT_dt"
      },
      "source": [
        "La perplejidad del conjunto de prueba utilizando los últimos coeficientes es:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaNKyVM2UFZM",
        "outputId": "99eed1b6-300b-4df4-89a4-ba1107ba2eb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "138.74684294224096"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interpolated_model.coeff = lambdas_history[-1]\n",
        "perplexity(interpolated_model, corpus_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k8f3LCzRJmV"
      },
      "source": [
        "Se puede ver cómo desde la primera iteración se obtuvo una convergencia. Además, también vimos que se minimizó la perplejidad un poco más comparando con los mejores coeficientes que se exploraron de manera manual en el ejercicio 3.3:\n",
        "\n",
        "- Coeficientes fijos ``[0.4, 0.3, 0.2, 0.1]`` -> perplejidad sobre el conjunto de prueba: 145.50\n",
        "- Coeficientes con EM ``[0.28502087, 0.40860887, 0.2124263 , 0.09394396]]`` -> perplejidad sobre el conjunto de prueba: 138.74\n",
        "\n",
        "En los coeficientes encontrados con EM vemos cómo el mayor peso de 0.4 se le asigna al modelo de bigramas, después al modelo de unigramas y trigramas con pesos similares de 0.2, y al modelo de tetragramas se le da un peso muy bajo de 0.09. De nuevo confirmando lo que decíamos que los modelos basados en n-gramas se basaban principalmente en unigramas, bigramas y trigramas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAgztmb2TxoX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsWFi2tUvJmz"
      },
      "source": [
        "### 4.2- Función para generar texto\n",
        "\n",
        "Haga una función \"generar texto\" con base en su modelo de lenguaje $\\hat{P}$ del último punto. El modelo deberá poder parar automáticamente cuando genere el símbolo de terminación de oración al final (e.g., ``</s>``), o 50 palabras. Proponga algo para que en los últimos tokens sea más probable generar el token ``</s>``. Muestre al menos cinco ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udRDax5rYIw7"
      },
      "source": [
        "---\n",
        "\n",
        "**EJERCICIO CON AYUDA DE LESLIE JANETH**\n",
        "\n",
        "Para generar el siguiente token, dado un contexto, calculamos las probabilidades condicionales de todo el vocabulario (excepto el token de inicio) y sampleamos una palabra de los top k tokens con mayor probabilidad y el token ``</s>`` (o sea, k+1 tokens en total para el sampling).\n",
        "\n",
        "La estrategia para aumentar la probabilidad del token ``</s>`` en los últimos tokens me la comentó **Leslie Quincosa**, y vi su código para darme una idea de cómo integrarla a mi código. Se trata de que después de una cierta iteración ``boost_threshold`` se multiplique la probabilidad del token ``</s>`` por un cierto factor ``boost_factor``.\n",
        "\n",
        "Antes de samplear, se deben normalizar las probabilidades ya que no sumarán 1 pues quitamos el token inicial ``<s>`` y porque en las últimas iteraciones también modificamos la probabilidad de ``</s>``.\n",
        "\n",
        "La siguiente función puede recibir una lista de tokens iniciales de tamaño n-1, donde $n$ es el tamaño de $n$-gramas más grande que se utiliza en un modelo interpolado (en nuestro caso $n=4$). Si no se manda la lista de tokens iniciales, se agregan n-1 tokens iniciales ``<s>``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "VfiqM5-FTykk"
      },
      "outputs": [],
      "source": [
        "def generate_text(\n",
        "    model: InterpolatedModel,\n",
        "    n_tokens: int = 50,\n",
        "    top_k : int = 1000,\n",
        "    boost_threshold: int = 45,\n",
        "    boost_fastor: float = 5,\n",
        "    seed: Optional[list[str]] = None\n",
        ") -> str:\n",
        "    if seed is None:\n",
        "        text = [model.text_processor.INIT_TKN] * (model.n - 1)\n",
        "    else:\n",
        "        if len(seed) != model.n - 1:\n",
        "            raise ValueError(\"seed should be of length n-1\")\n",
        "\n",
        "        text = list(map(model.text_processor.mask_oov, seed))\n",
        "\n",
        "    vocab = list(\n",
        "        model.text_processor.vocab - {model.text_processor.INIT_TKN}\n",
        "    )  # we quit the initial token\n",
        "\n",
        "    for i in range(n_tokens):\n",
        "        context = text[-model.n + 1 :]  # last n-1 tokens from generated text\n",
        "\n",
        "        probs = [\n",
        "            (w, model.conditional_prob(w, context))\n",
        "            for w in vocab\n",
        "            if w != model.text_processor.END_TKN\n",
        "        ]\n",
        "\n",
        "        probs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        words = [w for w, p in probs[:top_k]]\n",
        "        probs = [p for w, p in probs[:top_k]]\n",
        "\n",
        "        prob_end_tkn = model.conditional_prob(\n",
        "            model.text_processor.END_TKN, context\n",
        "        )\n",
        "\n",
        "        if i + 1 >= boost_threshold:\n",
        "            # increase </s> probability\n",
        "            prob_end_tkn *= boost_fastor\n",
        "\n",
        "        probs.append(prob_end_tkn)\n",
        "        words.append(model.text_processor.END_TKN)\n",
        "\n",
        "        # normalize probabilities, since we quit <s> token and they will not sum 1 (and also we may altered </s> probability)\n",
        "        total_prob = sum(probs)\n",
        "        probs = [p / total_prob for p in probs]\n",
        "\n",
        "        # we sample the next word according to the conditional probabilities\n",
        "        next_word = np.random.choice(words, p=probs).item() # .item() to get raw string (not numpy string)\n",
        "        text.append(next_word)\n",
        "\n",
        "        if next_word == model.text_processor.END_TKN:\n",
        "            break\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkFnWsMgeB6v"
      },
      "source": [
        "5 ejemplos, sampleando sobre los top 1000 (valor default de la función) tokens de mayor probabilidad:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDfz8Ae-Oubw",
        "outputId": "e14c8939-3e7b-4416-ab44-c6fc1289ee86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> <s> <s> mismo <unk> van del gabinete <unk> en tamaulipas <unk> que ellos total de cinco hacer eso sería mi sobrina unidos a <unk> por no el más al principio muy rápido estaba como datos que <unk> la secretaría pero <unk> va a beneficiar a enfrentar que cuidar a ciudadanos que no\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(10)\n",
        "print(\" \".join(generate_text(interpolated_model)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZCH60WieLBk",
        "outputId": "4a5ce055-dc6d-4a55-cefc-c1d48761c670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> <s> <s> <unk> etcétera <unk> programa denuncia los cuales <unk> el agua informa cosas que se puede debatir de no opino <unk> donde claudia sheinbaum <unk> </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(7)\n",
        "print(\" \".join(generate_text(interpolated_model)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T73WRDkdeLLx",
        "outputId": "d6538d85-aa75-4302-8bd1-fa34a03ce9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> <s> <s> de la gasolina eso se nos <unk> una hacienda estoy ahí <unk> </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(11)\n",
        "print(\" \".join(generate_text(interpolated_model)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TC5Q-9beLUH",
        "outputId": "0a15e171-0415-45a8-8271-1e06e009624b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> <s> <s> otro tema pendiente periódico </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(13)\n",
        "print(\" \".join(generate_text(interpolated_model)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djB59HFEeLfA",
        "outputId": "27c62388-ddca-401a-943d-1b1399104059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> <s> <s> la vez que se planteó yo siempre por ciento de influencia <unk> </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(17)\n",
        "print(\" \".join(generate_text(interpolated_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53pIyW_wfdsw"
      },
      "source": [
        "Se observa que en general no tiene sentido el texto generado, salvo en ciertas frases de longitud 3 o 4, por ejemplo: \"hacer eso sería\", \"donde claudia sheinbaum\" y \"otro tema pendiente\". Por cierto, tomar sólo los top-k tokens para samplear fue una mejor estrategia comparado con samplear sobre todo el vocabulario. Intenté al principio samplear sobre todo el vocabulario y el modelo no generaba cosas con sentido. Después intenté con varios valores de k, y encontré que 1000 era un buen número."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-KZF8VwTy5R"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3YAaQxmvJmz"
      },
      "source": [
        "### 4.3- Función para generar texto con semilla\n",
        "\n",
        "Haga una función \"generar texto con semilla\", que reciba tres tokens y a partir de ellos empiece a generar texto automáticamente con la misma política del punto anterior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOrZuYhZfoIk"
      },
      "source": [
        "---\n",
        "\n",
        "La función anterior ya tiene la opción para recibir una semilla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-cGrVycjcuP",
        "outputId": "ce6ce4c6-ac04-458f-9b66-b9ef2f8914de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "buenos días cómo enfrentar <unk> tienen tiempo se les da yo no <unk> ustedes llegaron <unk> ‘ necesito son sólo el haya ’ y de una medida a tener problemas para porque por otros es fueron la de méxico <unk> </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(10)\n",
        "print(\" \".join(generate_text(interpolated_model, seed = [\"buenos\", \"días\", \"cómo\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouzCXHWnjcuS",
        "outputId": "2e93d515-4f30-4693-c75e-acd1e4776131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "presidente andrés manuel lópez de salud por semanas más grande <unk> la nación ’ me dice <unk> el efecto <unk> hay trabajos de como dé de estas adquisiciones <unk> son le podría por la venta del consejo coordinador pueden nacional de ellos no tienen de otros tiempos del fraude la sería el cómo\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(7)\n",
        "print(\" \".join(generate_text(interpolated_model, seed = [\"presidente\", \"andrés\", \"manuel\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WJoeHE1jcuT",
        "outputId": "4dd945fe-5101-42cd-e5cd-5265a2319134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "la educación es que se nos informa a haber <unk> hay señal temas le voy arriba centavos <unk> ayer <unk> que el pueblo una ser una serie de la instrucción por ciento de el donde eso fue se continúe </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(11)\n",
        "print(\" \".join(generate_text(interpolated_model, seed = [\"la\", \"educación\", \"es\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidqzhqpjcuT",
        "outputId": "cd5a6c59-2ed4-4d43-9606-4bf930dd0e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "la mafia del imss vaya era la fiscalía los estados <unk> usted sabe <unk> </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(23)\n",
        "print(\" \".join(generate_text(interpolated_model, seed = [\"la\", \"mafia\", \"del\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2nx46l1jcuT",
        "outputId": "7a6a1165-7133-417a-91d8-6d023aa870c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bola de corruptos de cómo <unk> <unk> kilogramos todo se porque <unk> por cuanto a usar precios <unk> antes y ahí y el poder público de repente un la la <unk> saben que no yo también <unk> muy importante lo que están libres ejemplo <unk> </s>\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(17)\n",
        "print(\" \".join(generate_text(interpolated_model, seed = [\"bola\", \"de\", \"corruptos\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiUGCFj3lErM"
      },
      "source": [
        "Encontramos el mismo comportamiento que en el ejercicio pasado: no hay coherencia a nivel global pero sí se generan ciertas frases de tamaño 3 o 4 con cierto sentido. Por ejemplo, después de la semilla \"presidente andrés manuel\" el modelo predijo \"lópez\" como la siguiente palabra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re5Pf74TT0ME"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9QD5-ecvJmz"
      },
      "source": [
        "### 4.4- Top 5 de permutaciones más y menos probables\n",
        "\n",
        "Haga una función que reciba una oración, y que permute todos sus tokens, que los evalué todos con su modelo de lenguaje, y que muestre el top 5 más probable y el top 5 menos probable, por ejemplo, use las siguientes dos oraciones y una más que usted proponga: \"sino gano me voy a la chingada\", \"ya se va a acabar la corrupción\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTv2rVWaswvB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "QYyvdpLOT1Hn"
      },
      "outputs": [],
      "source": [
        "def top_5_permutations(model: InterpolatedModel, sentence: list[str]):\n",
        "    permuts = list(permutations(sentence))\n",
        "    probs = [(i, model.prob_sequence(perm)) for i, perm in enumerate(permuts)]\n",
        "    probs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"5 permutaciones más probables\")\n",
        "    for i in range(5):\n",
        "        print(f\"Permutación: {permuts[probs[i][0]]} - probabilidad {probs[i][1]}\")\n",
        "\n",
        "    print(\"\\n5 permutaciones menos probables\")\n",
        "    for i in range(5):\n",
        "        print(f\"Permutación: {permuts[probs[-i-1][0]]} - probabilidad {probs[-i-1][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUquRnqcswNg"
      },
      "source": [
        "Ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K0EaYlbsznj",
        "outputId": "06cf91d6-250f-4643-8c91-4b83a410c75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 permutaciones más probables\n",
            "Permutación: ('gano', 'chingada', 'sino', 'me', 'voy', 'a', 'la') - probabilidad 1.7495065427588989e-07\n",
            "Permutación: ('chingada', 'gano', 'sino', 'me', 'voy', 'a', 'la') - probabilidad 1.7495065427588989e-07\n",
            "Permutación: ('sino', 'gano', 'chingada', 'me', 'voy', 'a', 'la') - probabilidad 9.771204919810925e-08\n",
            "Permutación: ('gano', 'sino', 'chingada', 'me', 'voy', 'a', 'la') - probabilidad 9.771204919810925e-08\n",
            "Permutación: ('sino', 'chingada', 'gano', 'me', 'voy', 'a', 'la') - probabilidad 9.7694556163849e-08\n",
            "\n",
            "5 permutaciones menos probables\n",
            "Permutación: ('me', 'a', 'la', 'gano', 'sino', 'voy', 'chingada') - probabilidad 7.242773167347593e-19\n",
            "Permutación: ('me', 'a', 'la', 'gano', 'voy', 'chingada', 'sino') - probabilidad 7.433530787830064e-19\n",
            "Permutación: ('me', 'a', 'la', 'gano', 'voy', 'sino', 'chingada') - probabilidad 7.716713247758474e-19\n",
            "Permutación: ('me', 'a', 'la', 'gano', 'sino', 'chingada', 'voy') - probabilidad 8.054897817104227e-19\n",
            "Permutación: ('me', 'a', 'la', 'gano', 'chingada', 'voy', 'sino') - probabilidad 1.1374868980159479e-18\n"
          ]
        }
      ],
      "source": [
        "top_5_permutations(interpolated_model, [\"sino\", \"gano\", \"me\", \"voy\", \"a\", \"la\", \"chingada\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQKNB9ls5Qm",
        "outputId": "7e78d5b3-b864-43f3-c812-aa1fef9a8508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 permutaciones más probables\n",
            "Permutación: ('corrupción', 'acabar', 'ya', 'se', 'va', 'a', 'la') - probabilidad 2.1258048231672103e-05\n",
            "Permutación: ('acabar', 'corrupción', 'ya', 'se', 'va', 'a', 'la') - probabilidad 2.1258044742922328e-05\n",
            "Permutación: ('acabar', 'ya', 'se', 'va', 'a', 'la', 'corrupción') - probabilidad 3.4207132717377285e-06\n",
            "Permutación: ('ya', 'acabar', 'se', 'va', 'a', 'la', 'corrupción') - probabilidad 2.8496249574912944e-06\n",
            "Permutación: ('ya', 'acabar', 'corrupción', 'se', 'va', 'a', 'la') - probabilidad 2.7525522682623987e-06\n",
            "\n",
            "5 permutaciones menos probables\n",
            "Permutación: ('se', 'a', 'la', 'acabar', 'va', 'ya', 'corrupción') - probabilidad 2.5658971917728768e-15\n",
            "Permutación: ('se', 'a', 'la', 'acabar', 'va', 'corrupción', 'ya') - probabilidad 2.737725994629387e-15\n",
            "Permutación: ('a', 'se', 'la', 'acabar', 'va', 'ya', 'corrupción') - probabilidad 3.1119838374297877e-15\n",
            "Permutación: ('a', 'la', 'se', 'acabar', 'va', 'ya', 'corrupción') - probabilidad 3.1896915062615804e-15\n",
            "Permutación: ('la', 'a', 'se', 'acabar', 'va', 'ya', 'corrupción') - probabilidad 3.1903843487435217e-15\n"
          ]
        }
      ],
      "source": [
        "top_5_permutations(interpolated_model, [\"ya\", \"se\", \"va\", \"a\", \"acabar\", \"la\", \"corrupción\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gORvs1latNAn",
        "outputId": "3bdf1c0a-8f73-4f1a-ffee-13716de5cc50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 permutaciones más probables\n",
            "Permutación: ('presidente', 'los', 'estados', 'unidos', 'de') - probabilidad 0.005188333903081463\n",
            "Permutación: ('presidente', 'de', 'los', 'estados', 'unidos') - probabilidad 0.004510253939202986\n",
            "Permutación: ('los', 'presidente', 'estados', 'unidos', 'de') - probabilidad 0.004387904439836313\n",
            "Permutación: ('de', 'presidente', 'los', 'estados', 'unidos') - probabilidad 0.002149065859174432\n",
            "Permutación: ('los', 'presidente', 'de', 'estados', 'unidos') - probabilidad 0.0017581272819283706\n",
            "\n",
            "5 permutaciones menos probables\n",
            "Permutación: ('presidente', 'de', 'los', 'unidos', 'estados') - probabilidad 6.585041855677052e-08\n",
            "Permutación: ('los', 'presidente', 'de', 'unidos', 'estados') - probabilidad 6.701678219201393e-08\n",
            "Permutación: ('de', 'presidente', 'los', 'unidos', 'estados') - probabilidad 6.70616750774683e-08\n",
            "Permutación: ('presidente', 'los', 'de', 'unidos', 'estados') - probabilidad 6.709000345389876e-08\n",
            "Permutación: ('los', 'de', 'presidente', 'unidos', 'estados') - probabilidad 6.711093302874916e-08\n"
          ]
        }
      ],
      "source": [
        "top_5_permutations(interpolated_model, [\"presidente\", \"de\", \"los\", \"estados\", \"unidos\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT4d-R5YtcxZ"
      },
      "source": [
        "En los ejemplos se puede ver que las permutaciones que salen en el top 5 contienen frases con coherencia, y en las peores permutaciones no hay ninguna frase con coherencia. Por ejemplo, en la primera oración las permutaciones con mayor probabilidad contienen la frase  \"me voy a la\", lo cual es una frase con coherencia y por eso se le asigna una probabilidad alta. En la segunda oración las permutaciones top continenen la frase \"ya se va a la\", y en la tercera oración tienen la frase \"los estados unidos\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG730WXMT1Qr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdX9Bhs7vJmz"
      },
      "source": [
        "### 4.5- Top de 5 palabras más probables después de tres dadas.\n",
        "\n",
        "Haga una función que reciba tres palabras y regrese las siguientes 5 palabras más probables dadas las tres primeras. Muéstrelas en pantalla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_vQp268u9Z3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "0PUUSi3ET2Uk"
      },
      "outputs": [],
      "source": [
        "def top_5_word_after_context(model: InterpolatedModel, context: list[str]):\n",
        "    if len(context) != model.n - 1:\n",
        "        raise ValueError(\"context should be of length n-1\")\n",
        "\n",
        "    context = list(map(model.text_processor.mask_oov, context))\n",
        "\n",
        "    probs = [(w, model.conditional_prob(w, context)) for w in model.text_processor.vocab]\n",
        "    probs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(f\"Top 5 palabras más probables después de {context}\")\n",
        "    for i in range(5):\n",
        "        print(f\"Palabra: {probs[i][0]} - probabilidad {probs[i][1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRFgHz8-u_Tu"
      },
      "source": [
        "Ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhs2MDDIvADa",
        "outputId": "106836b0-304f-4ed5-9e87-0d6c35fdafd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 palabras más probables después de ['la', 'educación', 'es']\n",
            "Palabra: <unk> - probabilidad 0.048320691556252085\n",
            "Palabra: el - probabilidad 0.043479418196520556\n",
            "Palabra: que - probabilidad 0.04150031121550378\n",
            "Palabra: un - probabilidad 0.04112206623231236\n",
            "Palabra: la - probabilidad 0.038186814545824954\n"
          ]
        }
      ],
      "source": [
        "top_5_word_after_context(interpolated_model, [\"la\", \"educación\", \"es\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0vTA975vJS4",
        "outputId": "b88192a3-e373-49a6-d221-49d56491d011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 palabras más probables después de ['la', 'mafia', 'del']\n",
            "Palabra: <unk> - probabilidad 0.039022922159146226\n",
            "Palabra: gobierno - probabilidad 0.016518917026294436\n",
            "Palabra: estado - probabilidad 0.016320043733837362\n",
            "Palabra: poder - probabilidad 0.014137318295140372\n",
            "Palabra: país - probabilidad 0.013835593170272286\n"
          ]
        }
      ],
      "source": [
        "top_5_word_after_context(interpolated_model, [\"la\", \"mafia\", \"del\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1LqzMMwvMo2",
        "outputId": "198b2474-0571-4350-eee5-19a2b9bb3164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 palabras más probables después de ['andrés', 'manuel', 'lópez']\n",
            "Palabra: obrador - probabilidad 0.6301703440576965\n",
            "Palabra: <unk> - probabilidad 0.04005505401584125\n",
            "Palabra: de - probabilidad 0.012818338957356552\n",
            "Palabra: </s> - probabilidad 0.010104632108758586\n",
            "Palabra: <s> - probabilidad 0.010074783551905853\n"
          ]
        }
      ],
      "source": [
        "top_5_word_after_context(interpolated_model, [\"andrés\", \"manuel\", \"lópez\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kCRwB0bvfH2"
      },
      "source": [
        "Con estos ejemplos vemos que el top 5 de palabras después de un contexto dado (de longitud 3) hace sentido. Por ejemplo, el modelo le asigna una probabilidad alta a \"poder\" después de \"la mafia del\", y también a la palabra \"obrador\" después de \"andrés manuel lópez\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrRBMgKPT2cf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-u_03O7vJmz"
      },
      "source": [
        "## 5- El Ahorcado\n",
        "\n",
        "Para esta parte estudie y comprenda el funcionamiento de la estrategia propuesta por [Norvig](http://norvig.com/spell-correct.html). Siéntete libre de adaptar y/o extender parcial o totalmente el código de Norvig para esta tarea.\n",
        "Diseñe una función que sea capaz de encontrar los caracteres faltantes de una palabra. Para ello proponga una adaptación simple de la estrategia de corrección ortográfica propuesta por Norvig. La función de el ahorcado debe poder tratar con hasta 4 caracteres desconocidos en palabras de longitud arbitraria. La función debe trabajar en tiempo razonable (≈ 1 minuto en una laptop o menos). La función debe trabajar como sigue con 10 ejemplos:\n",
        "~~~\n",
        ">>> hangman(\"pe_p_e\")\n",
        "\"people\"\n",
        ">>> hangman(\"phi__sop_y\")\n",
        "\"philosophy\"\n",
        ">>> hangman(\" si_nif_c_nc_ \")\n",
        "\"significance\"\n",
        "~~~\n",
        "Puede resolver este punto con una extensión MUY simple (hasta la MÁS OBVIA) de la estrategia de Norvig, PERO HAY FORMAS MUCHO MÁS EFICIENTES (Si te sobra tiempo en la vida) con distancias de edición (e.g., Levenshtein) o de subcadenas (e.g., Karp Rabin, Aho-Corasick, Tries, etc.).\n",
        "\n",
        "Comente brevemente como integraría un modelo de lenguaje con el modelo de Norvig para tratar de resolver errores gramaticales de más alto nivel, o errores dónde el error sea una palabra que SÍ está en el diccionario, por ejemplo: *\"In the science off Maths ...\"*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0K4x-DOuiHb"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbuI7c_624U2"
      },
      "source": [
        "Para crear la función del ahorcado (``hangman``), vamos a utilizar expresion regulares (regex). En regex, el caracter \".\" sirve para hacer match a cualquier caracter. De manera que si reemplazamos los \"_\" por \".\" en una expresión regular, podemos encontrar todas las palabras en el vocabulario que tengan el patrón que recibe el ahorcado. A la expresión regular también le debemos agregar los caracteres de inicio (\"^\") y final de string (\"$\"). Después con nuestro modelo de unigramas previamente entrenado, podemos obtener la probabilidad de cada palabra que hizo match a la expresión regular, y la respuesta sería la de mayor probabilidad.\n",
        "\n",
        "Esta estrategia se inspira en la idea de Norvig ya que él busca palabras candidatas considerando los errores más comúnes: inserciones, eliminaciones, sustitucioenes y transposiciones de caracteres. Y después esas palabras las ordena de acuerdo a su probabilidad de unigrama (sin suavizado) en un corpus. Nosotros en vez de considerar los posibles errores, simplemente buscamos las palabras candidatas mediante la expresión regular que define el patrón del ahorcado (con la estrategia explicada en el párrafo pasado)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "4KOWpN4-yE8S"
      },
      "outputs": [],
      "source": [
        "def hangman(pattern: str) -> str:\n",
        "\n",
        "    # create regex pattern, replacing \"_\" by \".\" and adding start (\"^\") and end (\"$\") of string characters\n",
        "    regex = \"^\" + pattern.replace(\"_\", \".\") + \"$\"\n",
        "    # compile regex\n",
        "    regex = re.compile(regex)\n",
        "\n",
        "    # find matching words in vocabulary. regex.match(word) returns None if no matching\n",
        "    candidates = [word for word in unigram_model.text_processor.vocab if regex.match(word)]\n",
        "\n",
        "    # unigram probabilities\n",
        "    probs = [unigram_model.conditional_prob(word, []) for word in candidates]\n",
        "\n",
        "    max = 0\n",
        "    max_id = -1\n",
        "\n",
        "    for i in range(len(probs)):\n",
        "        if probs[i] > max:\n",
        "            max = probs[i]\n",
        "            max_id = i\n",
        "\n",
        "    return candidates[max_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCeDqg4X5ZIY"
      },
      "source": [
        "10 ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgEzQAWSyNm8",
        "outputId": "013b360c-5426-497e-fe44-95120c75e2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "presidente\n",
            "mafia\n",
            "corrupción\n",
            "andrés\n",
            "sheinbaum\n",
            "educación\n",
            "matutina\n",
            "estados\n",
            "ustedes\n",
            "hola\n"
          ]
        }
      ],
      "source": [
        "print(hangman(\"pr_s_de_te\"))\n",
        "print(hangman(\"m_f_a\"))\n",
        "print(hangman(\"cor_up_ió_\"))\n",
        "print(hangman(\"an___s\"))\n",
        "print(hangman(\"sh__nba_m\"))\n",
        "print(hangman(\"e_u_a_i__\"))\n",
        "print(hangman(\"mat_t_n_\"))\n",
        "print(hangman(\"e_t_d_s\"))\n",
        "print(hangman(\"ust_d__\"))\n",
        "print(hangman(\"h_l_\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWyrGr1uzG7E"
      },
      "source": [
        "Aquí en los ejemplos vemos que sí se está utilizando la probabilidad para determinar la respuesta. Por ejemplo, el patrón \"an___s\" tiene varias palabras posibles, algunas de ellas son: \"anchas\", \"andrés\" y \"ansias\". Pero la de mayor probabilidad, como esperamos, es \"andrés\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxoljzwA8XuO",
        "outputId": "c1971780-c4c0-4ab6-88e5-72ea4f24d5e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabra: anchas\n",
            "En vocabulario: True\n",
            "Probabilidad: 1.8128173926249346e-06 \n",
            "\n",
            "Palabra: andrés\n",
            "En vocabulario: True\n",
            "Probabilidad: 0.0025036911412510054 \n",
            "\n",
            "Palabra: ansias\n",
            "En vocabulario: True\n",
            "Probabilidad: 8.612072127693258e-07 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_words = [\"anchas\", \"andrés\", \"ansias\"]\n",
        "for word in test_words:\n",
        "    print(\"Palabra:\", word)\n",
        "    print(\"En vocabulario:\", word in unigram_model.text_processor.vocab)\n",
        "    print(\"Probabilidad:\", unigram_model.conditional_prob(word, []), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HfNFMXs83r4"
      },
      "source": [
        "Lo que se me ocurre para resolver errores en una oración es lo siguiente:\n",
        "\n",
        "1.   De la oración, suponer que cada palabra puede estar mal escrita.\n",
        "2.   Por cada palabra, intercambiar esa palabra por otra en el vocabulario y calcular la probabilidad de la oración con un modelo de lenguaje.\n",
        "3.   Así creamos una lista de oraciones que se obtiene al sustituir una palabra por otra en el vocabulario, y sus respectivas probabilidades.\n",
        "4.   Tomamos la oración con mayor probabilidad.\n",
        "\n",
        "Pero esta idea tiene un problema y es que no hay manera de determinar si la oración con mayor probabilidad tiene las palabras que se estaban buscando. Por ejemplo, en la oración \"In the science off Maths\" podemos obtener las siguientes alternativas:\n",
        "\n",
        "*   “In the science of Maths”\n",
        "*   \"In the science with Maths\"\n",
        "\n",
        "La primera oración es la que nos gustaría, pero la segunda oración podría ser resultado de este procedimiento. Una manera de corregir este problema es que en vez de sustituir una palabra de la oración por cualquier otra en el vocabulario, podemos tomar la idea de Norvig de considerar sólo candidatos con los errores más comúnes de escritura. Pero de todos modos el pipeline completo pienso que es costoso.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
